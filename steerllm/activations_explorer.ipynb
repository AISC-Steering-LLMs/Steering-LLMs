{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import stats\n",
    "from scipy.spatial.distance import cosine, euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This opens up a pkl file of activations from a contrastive honesty experiment using gpt-2-small. I haven't got llama working on my machine yet.\n",
    "\n",
    "Note, this dataset uses the word honesty in almost every prompt, rather than by capturing the spirit of honesty in general.\n",
    "\n",
    "Open up folder /data/outputs/2024-03-22_16-30-39 to see the dataset used, the config etc.\n",
    "\n",
    "No PCA or any kind of classification has been done.\n",
    "\n",
    "To look at integrity, open /data/outputs/2024-03-22_17-41-38 instead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Honesty\n",
    "with open('../data/outputs/2024-03-22_16-30-39/activations_cache.pkl', 'rb') as file:\n",
    "    acts = pickle.load(file)\n",
    "\n",
    "# Integrity\n",
    "# with open('../data/outputs/2024-03-22_17-41-38/activations_cache.pkl', 'rb') as file:\n",
    "#     acts = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is is list of 160 activations corresponding to the 160 prompts in the honesty dataset (150 for integrity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(activations_cache) <class 'list'>\n",
      "len(activations_cache):  160\n"
     ]
    }
   ],
   "source": [
    "print(\"type(activations_cache)\", type(acts))\n",
    "print(\"len(activations_cache): \", len(acts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each activation is of type Activation invented by Skye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(activations_cache[i]) <class 'data_handler.Activation'>\n"
     ]
    }
   ],
   "source": [
    "# Looking at the first activation:\n",
    "\n",
    "print(\"type(activations_cache[i])\", type(acts[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each activation has 5 components as currenrtly defined.\n",
    "\n",
    "- The stored prompt - a string\n",
    "- The ethical area - a string\n",
    "- The ethical valence - a bool\n",
    "- The raw activations (currenrtly does nothing) - a None type\n",
    "- The activations of the final token in each residual layer - a list of numpy arrays\n",
    "\n",
    "Let's look at the first 4 components in the ith example out of 160. Change i to any number between 0 and 159 for honesty (149 for integrity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What role does honesty play in building trust in a relationship? Definitely by withholding information to avoid conflict because,\n",
      "Ethical Area: Bad\n",
      "Positive: False\n",
      "Raw Activations: None\n"
     ]
    }
   ],
   "source": [
    "i = 0 # Set between 0 and 159 for the activation\n",
    "\n",
    "print(\"Prompt:\", acts[i].prompt)\n",
    "print(\"Ethical Area:\", acts[i].ethical_area)\n",
    "print(\"Positive:\", acts[i].positive)\n",
    "print(\"Raw Activations:\", acts[i].raw_activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the activations.\n",
    "\n",
    "- The activations are stored in a list\n",
    "- There are 12 of them for the 12 residual layers of gpt-2-small\n",
    "- The hidden state is a nunpy array of shape (768,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden States: <class 'list'>\n",
      "Hidden States: 12\n",
      "Hidden States: <class 'numpy.ndarray'>\n",
      "Hidden States: (768,)\n"
     ]
    }
   ],
   "source": [
    "i = 0 # Set between 0 and 159 for the activation\n",
    "j = 0 # Set between 0 and 11 for the residual layer\n",
    "\n",
    "print(\"Hidden States:\", type(acts[i].hidden_states))\n",
    "print(\"Hidden States:\", len(acts[i].hidden_states))\n",
    "print(\"Hidden States:\", type(acts[i].hidden_states[j]))\n",
    "print(\"Hidden States:\", acts[i].hidden_states[j].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the mean vector in each layer of each group (honest and dishonest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_mean_vectors(activations):\n",
    "    good_vectors = [[] for _ in range(12)]\n",
    "    bad_vectors = [[] for _ in range(12)]\n",
    "\n",
    "    for activation in activations:\n",
    "        if activation.ethical_area == \"Good\":\n",
    "            for i in range(12):\n",
    "                good_vectors[i].append(activation.hidden_states[i])\n",
    "        elif activation.ethical_area == \"Bad\":\n",
    "            for i in range(12):\n",
    "                bad_vectors[i].append(activation.hidden_states[i])\n",
    "\n",
    "    good_mean_vectors = [np.mean(np.array(vectors), axis=0) for vectors in good_vectors]\n",
    "    bad_mean_vectors = [np.mean(np.array(vectors), axis=0) for vectors in bad_vectors]\n",
    "\n",
    "    return good_mean_vectors, bad_mean_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_mean_vectors, bad_mean_vectors = calculate_mean_vectors(acts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check to make sure we have the right results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of good vectors: 12\n",
      "Number of bad vectors: 12\n",
      " \n",
      "Layer 0\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 1\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 2\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 3\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 4\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 5\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 6\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 7\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 8\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 9\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 10\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n",
      "Layer 11\n",
      "Types: <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "Shapes: (768,) (768,) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of good vectors:\", len(good_mean_vectors))\n",
    "print(\"Number of bad vectors:\", len(bad_mean_vectors))\n",
    "print(\" \")\n",
    "\n",
    "for i in range(len(good_mean_vectors)):\n",
    "    print(\"Layer\", i)\n",
    "    print(\"Types:\", type(good_mean_vectors[i]), type(bad_mean_vectors[i]))\n",
    "    print(\"Shapes:\", good_mean_vectors[i].shape, bad_mean_vectors[i].shape, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some stats of the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_array(arr):\n",
    "    descr = {\n",
    "        'mean': np.mean(arr),\n",
    "        'median': np.median(arr),\n",
    "        'std': np.std(arr),\n",
    "        'min': np.min(arr),\n",
    "        'max': np.max(arr),\n",
    "        '25%': np.percentile(arr, 25),\n",
    "        '50%': np.percentile(arr, 50),\n",
    "        '75%': np.percentile(arr, 75),\n",
    "        'skewness': stats.skewness(arr),\n",
    "        'kurtosis': stats.kurtosis(arr)\n",
    "    }\n",
    "    return descr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0\n",
      "Good Summary: {'mean': -1.4901161e-08, 'median': -0.003070693, 'std': 1.833413, 'min': -24.02176, 'max': 21.859676, '25%': -0.3186674565076828, '50%': -0.0030706928810104728, '75%': 0.31166715919971466, 'skewness': -1.449660487608728, 'kurtosis': 94.86374201458655}\n",
      "Bad Summary: {'mean': -2.483527e-09, 'median': -0.014793001, 'std': 1.8481566, 'min': -24.075228, 'max': 22.077213, '25%': -0.31616707146167755, '50%': -0.014793001115322113, '75%': 0.31988484412431717, 'skewness': -1.3696944270107592, 'kurtosis': 94.02596487760489} \n",
      "\n",
      "Layer 1\n",
      "Good Summary: {'mean': -1.4901161e-08, 'median': 0.023868494, 'std': 1.8881067, 'min': -26.126984, 'max': 21.059116, '25%': -0.41347939521074295, '50%': 0.023868493735790253, '75%': 0.41283509135246277, 'skewness': -1.766427162389191, 'kurtosis': 90.414382541948}\n",
      "Bad Summary: {'mean': -9.934108e-09, 'median': 0.006777445, 'std': 1.907903, 'min': -26.324163, 'max': 20.9573, '25%': -0.4333321303129196, '50%': 0.006777445087209344, '75%': 0.422514908015728, 'skewness': -1.7748265871992457, 'kurtosis': 88.5638044793687} \n",
      "\n",
      "Layer 2\n",
      "Good Summary: {'mean': 4.967054e-09, 'median': 0.016626012, 'std': 1.9846243, 'min': -26.195414, 'max': 23.391005, '25%': -0.5107880234718323, '50%': 0.01662601064890623, '75%': 0.5991521626710892, 'skewness': -0.9584774395788419, 'kurtosis': 83.68046043691787}\n",
      "Bad Summary: {'mean': 9.934108e-09, 'median': 0.025898779, 'std': 2.0037792, 'min': -26.346725, 'max': 23.253729, '25%': -0.5119338929653168, '50%': 0.025898778811097145, '75%': 0.6009644269943237, 'skewness': -0.9364915897975971, 'kurtosis': 81.09471004077294} \n",
      "\n",
      "Layer 3\n",
      "Good Summary: {'mean': -9.934108e-09, 'median': 0.061688595, 'std': 2.235696, 'min': -26.317532, 'max': 29.591986, '25%': -0.7537459284067154, '50%': 0.06168859452009201, '75%': 0.8526817411184311, 'skewness': 0.8109201748446342, 'kurtosis': 75.43233424941793}\n",
      "Bad Summary: {'mean': -2.9802322e-08, 'median': 0.067358345, 'std': 2.2860084, 'min': -26.476048, 'max': 30.318771, '25%': -0.8546525985002518, '50%': 0.0673583447933197, '75%': 0.8619460463523865, 'skewness': 0.9641232459401973, 'kurtosis': 73.60320829150974} \n",
      "\n",
      "Layer 4\n",
      "Good Summary: {'mean': -1.4901161e-08, 'median': 0.04953222, 'std': 2.4143584, 'min': -26.25824, 'max': 31.458324, '25%': -0.9449021518230438, '50%': 0.049532219767570496, '75%': 0.9807130843400955, 'skewness': 1.084224291373028, 'kurtosis': 63.56964919454981}\n",
      "Bad Summary: {'mean': -1.4901161e-08, 'median': 0.07073264, 'std': 2.4887044, 'min': -26.455896, 'max': 32.91179, '25%': -0.9411555230617523, '50%': 0.07073263451457024, '75%': 0.9941470921039581, 'skewness': 1.3366727204289435, 'kurtosis': 63.62510720482969} \n",
      "\n",
      "Layer 5\n",
      "Good Summary: {'mean': 1.4901161e-08, 'median': -0.009040333, 'std': 2.6049821, 'min': -26.577068, 'max': 30.499226, '25%': -1.1839426755905151, '50%': -0.009040333097800612, '75%': 1.1752354204654694, 'skewness': 0.6724531994795214, 'kurtosis': 43.6324920204865}\n",
      "Bad Summary: {'mean': -2.4835268e-08, 'median': 0.020630218, 'std': 2.6814568, 'min': -26.87321, 'max': 32.622074, '25%': -1.2648930549621582, '50%': 0.020630217157304287, '75%': 1.1925768554210663, 'skewness': 0.9742230552034443, 'kurtosis': 46.41031769723627} \n",
      "\n",
      "Layer 6\n",
      "Good Summary: {'mean': 0.0, 'median': -0.029707951, 'std': 2.9321823, 'min': -26.56951, 'max': 36.219803, '25%': -1.3849078118801117, '50%': -0.029707951471209526, '75%': 1.4353257417678833, 'skewness': 1.3601909135390542, 'kurtosis': 42.03923344669821}\n",
      "Bad Summary: {'mean': -3.4769375e-08, 'median': -0.027014926, 'std': 2.9872997, 'min': -26.843195, 'max': 37.75373, '25%': -1.3417983651161194, '50%': -0.02701492700725794, '75%': 1.384829044342041, 'skewness': 1.5631528885401769, 'kurtosis': 44.61546945911177} \n",
      "\n",
      "Layer 7\n",
      "Good Summary: {'mean': -3.4769375e-08, 'median': 0.025400762, 'std': 3.430785, 'min': -26.807901, 'max': 39.316677, '25%': -1.778363287448883, '50%': 0.02540076058357954, '75%': 1.8015795350074768, 'skewness': 1.1322149950557925, 'kurtosis': 29.348208067774394}\n",
      "Bad Summary: {'mean': -3.973643e-08, 'median': 0.03996388, 'std': 3.544329, 'min': -27.076412, 'max': 42.26653, '25%': -1.8240416944026947, '50%': 0.03996387682855129, '75%': 1.7157731354236603, 'skewness': 1.4140270724085597, 'kurtosis': 32.709014150755756} \n",
      "\n",
      "Layer 8\n",
      "Good Summary: {'mean': -2.9802322e-08, 'median': 0.017993651, 'std': 4.0510235, 'min': -26.917349, 'max': 46.862617, '25%': -2.0256046652793884, '50%': 0.017993652261793613, '75%': 1.9817894399166107, 'skewness': 1.3852613254918316, 'kurtosis': 30.350186553703118}\n",
      "Bad Summary: {'mean': -9.934108e-09, 'median': -0.100405216, 'std': 4.253115, 'min': -28.879734, 'max': 49.947044, '25%': -2.087547719478607, '50%': -0.10040521249175072, '75%': 2.0666890740394592, 'skewness': 1.490063059968201, 'kurtosis': 31.52158442799888} \n",
      "\n",
      "Layer 9\n",
      "Good Summary: {'mean': 0.0, 'median': -0.05249814, 'std': 5.5442266, 'min': -54.835533, 'max': 63.712524, '25%': -2.490395188331604, '50%': -0.052498139441013336, '75%': 2.22639924287796, 'skewness': 1.5528878716763075, 'kurtosis': 45.994931066468666}\n",
      "Bad Summary: {'mean': -1.9868216e-08, 'median': -0.15720561, 'std': 5.9202213, 'min': -59.49975, 'max': 69.44753, '25%': -2.525132954120636, '50%': -0.15720561146736145, '75%': 2.4307146072387695, 'skewness': 1.6831310635828285, 'kurtosis': 49.19605049334188} \n",
      "\n",
      "Layer 10\n",
      "Good Summary: {'mean': -1.9868216e-08, 'median': -0.11428282, 'std': 7.7914934, 'min': -79.54457, 'max': 95.259186, '25%': -2.7563632130622864, '50%': -0.11428281664848328, '75%': 2.4392635226249695, 'skewness': 3.752736974836065, 'kurtosis': 71.23418832412646}\n",
      "Bad Summary: {'mean': -3.973643e-08, 'median': -0.28306454, 'std': 8.13751, 'min': -82.39272, 'max': 101.39045, '25%': -2.998494029045105, '50%': -0.2830645442008972, '75%': 2.5475205183029175, 'skewness': 3.8248262378912004, 'kurtosis': 71.75950966511424} \n",
      "\n",
      "Layer 11\n",
      "Good Summary: {'mean': 0.0, 'median': -0.20400412, 'std': 14.8647585, 'min': -108.11449, 'max': 243.46179, '25%': -2.9093315601348877, '50%': -0.20400412380695343, '75%': 2.6913022994995117, 'skewness': 5.596439274663063, 'kurtosis': 112.7950287045487}\n",
      "Bad Summary: {'mean': 3.973643e-08, 'median': -0.12894142, 'std': 15.560927, 'min': -115.4715, 'max': 254.10274, '25%': -3.123063623905182, '50%': -0.12894140928983688, '75%': 2.703621506690979, 'skewness': 5.401739810628448, 'kurtosis': 111.88975571896047} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(good_mean_vectors)):\n",
    "    \n",
    "    print(\"Layer\", i)\n",
    "    good_summary = describe_array(good_mean_vectors[i])\n",
    "    bad_summary = describe_array(bad_mean_vectors[i])\n",
    "\n",
    "    print(\"Good Summary:\", good_summary)\n",
    "    print(\"Bad Summary:\", bad_summary, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare them using linear algebra\n",
    "\n",
    "- **Cosine Similarity:** Closer to 1 means the \"good\" and \"bad\" mean vectors are pointing in the same direction, indicating similar orientations in the vector space. A value near 0 indicates low similarity in direction, and a value closer to -1 would suggest they are diametrically opposed.\n",
    "- **Euclidean Distance:** A smaller distance indicates that the \"good\" and \"bad\" mean vectors are closer to each other in the vector space, suggesting they are more similar in both magnitude and direction. Larger distances indicate greater differences.\n",
    "- **ToDo:** Consider the meaning of other distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0\n",
      "Cosine Similarity: 0.0006571412086486816\n",
      "Euclidean Distance: 1.8938640356063843\n",
      "\n",
      "Layer 1\n",
      "Cosine Similarity: 0.0007013082504272461\n",
      "Euclidean Distance: 2.0448224544525146\n",
      "\n",
      "Layer 2\n",
      "Cosine Similarity: 0.0015034079551696777\n",
      "Euclidean Distance: 3.076526403427124\n",
      "\n",
      "Layer 3\n",
      "Cosine Similarity: 0.0023521780967712402\n",
      "Euclidean Distance: 4.517683982849121\n",
      "\n",
      "Layer 4\n",
      "Cosine Similarity: 0.002910792827606201\n",
      "Euclidean Distance: 5.5775580406188965\n",
      "\n",
      "Layer 5\n",
      "Cosine Similarity: 0.005340754985809326\n",
      "Euclidean Distance: 7.8608574867248535\n",
      "\n",
      "Layer 6\n",
      "Cosine Similarity: 0.00594329833984375\n",
      "Euclidean Distance: 9.07174015045166\n",
      "\n",
      "Layer 7\n",
      "Cosine Similarity: 0.007553160190582275\n",
      "Euclidean Distance: 12.287116050720215\n",
      "\n",
      "Layer 8\n",
      "Cosine Similarity: 0.0119742751121521\n",
      "Euclidean Distance: 18.66167640686035\n",
      "\n",
      "Layer 9\n",
      "Cosine Similarity: 0.011975109577178955\n",
      "Euclidean Distance: 26.68912696838379\n",
      "\n",
      "Layer 10\n",
      "Cosine Similarity: 0.00983816385269165\n",
      "Euclidean Distance: 32.40481185913086\n",
      "\n",
      "Layer 11\n",
      "Cosine Similarity: 0.003910958766937256\n",
      "Euclidean Distance: 41.9726676940918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(good_mean_vectors)):\n",
    "    print(\"Layer\", i)\n",
    "    print(\"Cosine Similarity:\", cosine(good_mean_vectors[i], bad_mean_vectors[i]))\n",
    "    print(\"Euclidean Distance:\", euclidean(good_mean_vectors[i], bad_mean_vectors[i]))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at the overall good and bad mean across all layers together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of the 12 mean good vectors\n",
    "overall_good_mean = np.mean(good_mean_vectors, axis=0)\n",
    "\n",
    "# Calculate the mean of the 12 mean bad vectors\n",
    "overall_bad_mean = np.mean(bad_mean_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768,)\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "print(overall_good_mean.shape)\n",
    "print(overall_bad_mean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': 0.0,\n",
       " 'median': -0.01116086,\n",
       " 'std': 3.630252,\n",
       " 'min': -35.297047,\n",
       " 'max': 43.8481,\n",
       " '25%': -1.278670608997345,\n",
       " '50%': -0.011160859372466803,\n",
       " '75%': 1.0942615866661072,\n",
       " 'skewness': 1.4778568832638104,\n",
       " 'kurtosis': 58.38198206992106}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_good_summary = describe_array(overall_good_mean)\n",
    "overall_good_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': -9.934108e-09,\n",
       " 'median': -0.070707634,\n",
       " 'std': 3.773382,\n",
       " 'min': -36.8757,\n",
       " 'max': 45.75711,\n",
       " '25%': -1.3445407450199127,\n",
       " '50%': -0.07070763781666756,\n",
       " '75%': 1.2200306951999664,\n",
       " 'skewness': 1.5253713198430263,\n",
       " 'kurtosis': 58.52324532013599}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_bad_summary = describe_array(overall_bad_mean)\n",
    "overall_bad_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.005172789096832275\n",
      "Euclidean Distance: 11.161230087280273\n"
     ]
    }
   ],
   "source": [
    "print(\"Cosine Similarity:\", cosine(overall_good_mean, overall_bad_mean))\n",
    "print(\"Euclidean Distance:\", euclidean(overall_good_mean, overall_bad_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could also compare honesty and integrity vectors\n",
    "# Plots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
