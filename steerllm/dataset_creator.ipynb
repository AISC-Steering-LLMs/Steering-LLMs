{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo:\n",
    "\n",
    "# Have working on Colab\n",
    "\n",
    "# General usability.\n",
    "\n",
    "# General form layout imprvements.\n",
    "\n",
    "# Make sure the instructions are clear and concise\n",
    "\n",
    "# Sort the placeholder ordering to reflect the order in the template\n",
    "\n",
    "# Put all background code in a DataGenerator class\n",
    "\n",
    "# General code quality\n",
    "# - probably some repeated code between forms that could be refactored\n",
    "# - much of the form code stitched together from LLM generated code for fast prototyping\n",
    "# --- Is it all necessary?\n",
    "# --- Can it be improved?\n",
    "# --- Does it make sense?\n",
    "\n",
    "# Don't allow saving as .csv.json in labelling form\n",
    "\n",
    "# Prompt novelty\n",
    "# --- random seed but record seeds\n",
    "# --- length\n",
    "# --- Sample from top 5?\n",
    "# --- higher shot in k-shot\n",
    "# --- bigger model - more expensive\n",
    "\n",
    "# Pick up from where we left off of API call fails\n",
    "# Do you loose everything if you stop the API call?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to use a prompt given to some LLM (\"LLM A\") to generate a dataset of different prompts to be fed to some other LLM (\"LLM B\" - potentially the same as \"LLM A\") for which you have access to the weights. This dataset of prompts will be used to create a \"representation vector\" of a property or concept for LLM B in order to \"steer\" LLM B to have more of that property or concept in its outputs. This Notebook does not cover the creation of representations or steering, only the the creation of a dataset of prompts.\n",
    "\n",
    "The kinds of prompts you want to generate should be about the property or concept you want to steer the LLM towards, not necessary literally mentioning it - e.g. prompts about politeness do not necessarily need to have the word polite in them. Part of the point of dataset creation is to explore which kinds of generated prompts yield good representations.\n",
    "\n",
    "The Notebook works as follows:\n",
    "\n",
    "- The Setup section loads Python libraries needed to run the code. You do not need to change anything here.\n",
    "- The Inputs section is where you define the prompt you will use to generate your dataset of prompts. Instructions on how to do this are given. This is the only section of the notebook where you will need to change anything.\n",
    "- The Review section then generates a small example dataset of prompts and shows them to you. If you like them, continue on to the end of the Notebook.\n",
    "- If you do not like them, please go back to the Inputs section to refine your prompt to generate your dataset of prompts.\n",
    "- The Dataset Generation section completes the dataset generation.\n",
    "- The View Dataset section loads your generated dataset for inspection.\n",
    "- Your dataset will be stored in /data/inputs/name_of_your_dataset/dataset if you want to use it later.\n",
    "\n",
    "The datasets will be generated in CSV format and should have the following form, where the first line is the column headings and subsequent lines are for example prompts. The columns ethical_area and ethical_valence are two different labels (classifications) of the prompt. The Notebook will help you generate these labels. This example is for \"politeness\" prompts:\n",
    "\n",
    "```\n",
    "prompt, ethical_area, ethical_valence\n",
    "\"Would you be so kind as to pass the water please.\", \"polite\", 1\n",
    "\"Give me the water now.\", \"impolite\", 0\n",
    "```\n",
    "\n",
    "If this is too restrictive, you will be able to create other columns and the notebook will ask you about that too.\n",
    "\n",
    "Note that where we have text, such as for the prompt or ethical_area, we want it enclosed in quote marks. Lone numbers do not need this.\n",
    "\n",
    "If there is something unusual you want to do that the current notebook does not permist, please ask, or feel free to try adding code for it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup (just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "#import main\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import yaml\n",
    "from hydra import initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.experimental import compose\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# For refactored code\n",
    "# Need to tidy this up and remove duplicates\n",
    "\n",
    "# from data_handler import DataHandler\n",
    "# from data_analyser import DataAnalyzer\n",
    "# from model_handler import ModelHandler\n",
    "\n",
    "#from sklearn.manifold import TSNE\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.cluster import FeatureAgglomeration\n",
    "\n",
    "# For datsaet generation\n",
    "import IPython\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "\n",
    "import yaml\n",
    "from ipywidgets import widgets, VBox, Button, Checkbox, Text, IntText, FloatText, SelectMultiple, Label\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything you might need to alter to change your prompt dataset generation requirements is in this inputs section of the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!CAUTION!!! Enter below your OpenAI API key within the quote marks \" \".\n",
    "\n",
    "- This is not safe practice but will allow the Notebook to run.\n",
    "- Better practice is to store the key in your environment variables. Please ask if you would like help with this.\n",
    "- If you plan to push or share this code in any other way, make sure to remove your API key from this section.\n",
    "\n",
    "```\n",
    "client = OpenAI(\n",
    "    api_key=\"your_api_key_goes_here\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI(\n",
    "#    api_key=\"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\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell represents the better practice for using your API key if it is saved in your environment variables.\n",
    "\n",
    "- This code is currenty \"commented out\" (has the # symbol in front of each line). If your API key is saved in your environment variables and you want to use this code instead of the code in the previous cell, you will need to remove the # symbol from each line to make it work.\n",
    "- There will be nothing to add to this code beyond removing the # symbols.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the name of the OpenAI model to use within the quote marks.\n",
    "\n",
    "- Select the model from the list of allowable models in the OpenAI API given your subscription level (create an account and get an API ket here: https://auth0.openai.com/u/signup/identifier?state=hKFo2SA1REJ3dGFZVTllNHFvYUFkY2RrWEJpUUVMUWxvel91VqFur3VuaXZlcnNhbC1sb2dpbqN0aWTZIFg1Z2NKOU9hUk4yYUFmWGxyTHlscmtNTmMxbDF5dWZTo2NpZNkgRFJpdnNubTJNdTQyVDNLT3BxZHR3QjNOWXZpSFl6d0Q).\n",
    "- You will need to put some token amount of money on to use gpt-4-0125-preview. It's something like $1. Might be $10.\n",
    "- This is unlikely to change unless the list of available models is updated. See here for the list of models: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4-0125-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the model temperature. \n",
    "\n",
    "- From the OpenAI API documentation (https://platform.openai.com/docs/guides/text-generation/how-should-i-set-the-temperature-parameter): \"Lower values for temperature result in more consistent outputs (e.g. 0.2), while higher values generate more diverse and creative results (e.g. 1.0). Select a temperature value based on the desired trade-off between coherence and creativity for your specific application. The temperature can range is from 0 to 2.\"\n",
    "- If your generated sentences are too similar/boring, try increasing the number. Go the other way if too wacky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the filename (or \"filestem\" as written below) without the file extension (e.g. .csv) to save the dataset to.\n",
    "\n",
    "- Don't worry about the file ending. It will be a csv. If you call your filename \"honesty\", then your dataset will be in honesty.csv.\n",
    "- Try to give it a specific name e.g. \"honesty_v2.csv\" or \"honesty_pairs_v2.csv\", something that will help you remember what it is especially if you are experimenting with variations.\n",
    "- Giving it the same name as an existing dataset will currently overwrite the existing dataset. It should always end in \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filestem = \"honesty\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the total number of prompts you want to generate in your dataset of prompts.\n",
    "\n",
    "- We are about to use a prompt to generate a datset of prompt examples.\n",
    "- If you want to generate 10 prompts in total, put 10 here.\n",
    "- If you want to generate 1000 prompts in total, put 1000 here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_examples = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the number of examples per request. This is the number of prompt examples you want to generate in one request to the LLM.\n",
    "\n",
    "- This is different from the total_num_examples variable you entered above.\n",
    "- The reason we have this is because the LLM has a limit on the number of tokens it can process in one request. If you put a number that is too high here, you will not get the number of prompts you want.\n",
    "- The number of tokens for gpt-4-0125-preview is 128,000 based on details given here: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo.\n",
    "- From a quick internet search, I think this model uses about 1.3 tokens per word. So you might have about 4096/1.3 = 98,461 words to play with if using this model. Remember, the number of tokens or words includes those in the prompt.\n",
    "- This should be more than enough to generate your entire dataset in one go, so you could try setting num_examples_per_request to the same number as total_num_examples. One reason to err on slightly fewer examples is that bigger responses from OpenAI take longer to generate. If you lose your internet connection before generation has ended, you lose your entire generated dataset. If you generate the data in small batches, you will have a partially complete dataset up until the batch that fails.\n",
    "- This Notebook will make sure that the total number of examples you want to generate as defined in total_num_examples are generated, but it will make multiple requests to the LLM. Eg if you made total_num_examples = 100 and num_examples_per_request = 5, then this code will automatically make 100/5 = 20 requests to the LLM to generate the 100 examples you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_per_request = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use or modify an existing templete, or to create a new one, run all the cells below up to and including the one with the code Initialize() in it.\n",
    "\n",
    "What is a template?\n",
    "- A generic prompt stucture.\n",
    "- Any variable/placeholder you might want to pass to your template should be include within a pair of braces like so: {{ your_variable_name }}\n",
    "\n",
    "To create a new template (this could be better):\n",
    "- Use the default blank_template.j2\n",
    "- Enter the template structure in the text box below the dropdown.\n",
    "- Create a new filename and click save\n",
    "- You cannot name a file blank_template.j2 and will be prompted to create a new file.\n",
    "- You can overwirte other existing template filenames but will recieve a warning beforehand that you are trying to overwrite and existing file. It is recommended that you always use a new filename for your new template for the sake of tracking experiments.\n",
    "- You can enter any filename you like with anyfile ending, but the file will always be saved as a .j2 file. E.g. if you save the file as politeness_template.md, it will get saved as politeness_template.txt. If you don;t supply a file ending, .txt will also be added.\n",
    "- To be able to use this saved template with a new name, you will need to make sure it is selected in the original dropdown menu at the top of the form. E.g. if you started with blank_template.j2 in the dropdown, created a new template and saved it as politeness_template.txt, you will need to go back to the top dropdown menu and select the now present politeness_template.txt.\n",
    "- You can now clock the Use Template Button.\n",
    "- Note: you can also create a new template using the template modification steps outlined next.\n",
    "\n",
    "To modify an existing template:\n",
    "- Select the desired template from the dropdown menu.\n",
    "- Clicking on the template will load it into the the text box below the dropdown.\n",
    "- Modify as needed.\n",
    "- The same comments about saving apply as to creating a new template mentioned above.\n",
    "- The same comments about using the template apply as to creating a new template mentioned above.\n",
    "\n",
    "To use an existing template without modification:\n",
    "- Select the desired template from the dropdown menu.\n",
    "- Do not change any text loaded into the the text box below the dropdown.\n",
    "- You do not need to save the existing template.\n",
    "- Click directly on the Use Template button.\n",
    "\n",
    "With the Use Template button clicked:\n",
    "- You will be asked to enter specific values for any variable/placeholder you have in your template.\n",
    "- This turns your prompt template into a specific prompt.\n",
    "- You will also be asked to enter a new filename to save the prompt.\n",
    "- The same saving rules apply to prompts as to templates described above, only the code forces saving the prompt as a .txt and not a .js.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just want to work with an existing template and not load it, ignore the last cell and run this one.\n",
    "\n",
    "- Select the template you want.\n",
    "- You will be prompted to enter values for your variables/placeholders.\n",
    "- You will also be asked to save this prompt (where templates and prompts are saved and how they can be related needs to \n",
    "be thought about).\n",
    "- Create a new filename and click save.\n",
    "- You cannot overwirte existing prompts. New prompts have to be saved with new names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ipywidgets import Dropdown, Textarea, Button, VBox, Label, Text, Output, HBox, Layout, widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from jinja2 import Environment, FileSystemLoader, meta\n",
    "from IPython import get_ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .widget-label {\n",
       "        white-space: normal;\n",
       "        word-wrap: break-word;\n",
       "        overflow-wrap: break-word;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('''\n",
    "<style>\n",
    "    .widget-label {\n",
    "        white-space: normal;\n",
    "        word-wrap: break-word;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "</style>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Jinja environment\n",
    "template_dir = '../data/inputs/templates'\n",
    "output_dir = '../data/inputs/prompts'\n",
    "env = Environment(loader=FileSystemLoader(template_dir))\n",
    "\n",
    "def load_templates():\n",
    "    \"\"\"Load template files from the template directory.\"\"\"\n",
    "    return [os.path.splitext(f)[0] for f in os.listdir(template_dir) if f.endswith('.j2')]\n",
    "\n",
    "def create_template_dropdown():\n",
    "    \"\"\"Create a dropdown widget for selecting templates.\"\"\"\n",
    "    templates = load_templates()\n",
    "    default_template = 'blank_template'\n",
    "    return Dropdown(options=templates, value=default_template if default_template in templates else None)\n",
    "\n",
    "def create_template_content_input():\n",
    "    \"\"\"Create a textarea widget for editing template content.\"\"\"\n",
    "    return Textarea(rows=10)\n",
    "\n",
    "def create_filename_input():\n",
    "    \"\"\"Create a text input widget for entering a new template filename.\"\"\"\n",
    "    return Text(value='new_template')\n",
    "\n",
    "def create_save_button():\n",
    "    \"\"\"Create a button widget for saving the template.\"\"\"\n",
    "    button = Button(description='Save Template')\n",
    "    button.on_click(save_template)\n",
    "    return button\n",
    "\n",
    "def create_use_button():\n",
    "    \"\"\"Create a button widget for using the template.\"\"\"\n",
    "    button = Button(description='Use Template')\n",
    "    button.on_click(use_template)\n",
    "    return button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_template(button):\n",
    "    \"\"\"Save the template content to a file.\"\"\"\n",
    "\n",
    "    # Replace any file extension from the text, if existent, with .j2\n",
    "    new_filename = filename_input.value.split('.')[0] + '.j2'\n",
    "    new_template_path = os.path.join(template_dir, new_filename)\n",
    "    if new_filename == \"blank_template.j2\":\n",
    "        with save_warning_output:\n",
    "            print('Cannot overwrite the \"blank_template.j2\" file.')\n",
    "    elif os.path.exists(new_template_path):\n",
    "        with save_warning_output:\n",
    "            print(f'File \"{new_filename}\" already exists. Do you want to overwrite it?')\n",
    "            overwrite_button = Button(description='Overwrite')\n",
    "            overwrite_button.on_click(lambda _: save_template_content(new_template_path, True))\n",
    "            cancel_button = Button(description='Cancel')\n",
    "            cancel_button.on_click(lambda _: save_warning_output.clear_output())\n",
    "            display(overwrite_button, cancel_button)\n",
    "    else:\n",
    "        save_template_content(new_template_path)\n",
    "\n",
    "def save_template_content(file_path, overwrite=False):\n",
    "    \"\"\"Save the template content to the specified file path.\"\"\"\n",
    "\n",
    "    template_content = template_content_input.value\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(template_content)\n",
    "    with success_output:\n",
    "        clear_output()\n",
    "        print(f'Template saved as \"{os.path.basename(file_path)}\".')\n",
    "    \n",
    "    if not overwrite:\n",
    "        # Refresh the template dropdown\n",
    "        template_dropdown.options = load_templates()\n",
    "\n",
    "        new_template_name = os.path.basename(file_path).split('.')[0]\n",
    "        template_dropdown.value = new_template_name\n",
    "\n",
    "def load_template_content(change):\n",
    "    \"\"\"Load the content of the selected template into the template content input.\"\"\"\n",
    "\n",
    "    template_name = change['new'] + '.j2'\n",
    "    template_path = os.path.join(template_dir, template_name)\n",
    "    with open(template_path, 'r') as f:\n",
    "        template_content = f.read()\n",
    "    template_content_input.value = template_content\n",
    "\n",
    "def render_template(template_name, user_input):\n",
    "    \"\"\"Render the template with the provided user input.\"\"\"\n",
    "    template = env.get_template(template_name)\n",
    "    return template.render(**user_input)\n",
    "\n",
    "def use_template(button):\n",
    "    \"\"\"Use the selected template and prompt the user to fill in the\n",
    "    template variables.\"\"\"\n",
    "\n",
    "    template_name = template_dropdown.value + '.j2'\n",
    "    template_source = env.loader.get_source(env, template_name)[0]\n",
    "    parsed_content = env.parse(template_source)\n",
    "    variables = meta.find_undeclared_variables(parsed_content)\n",
    "\n",
    "    load_form = VBox()\n",
    "    placeholders = {}\n",
    "    for var in variables:\n",
    "        placeholder_input = Text(\n",
    "            description=f'Enter value for \"{var}\":',\n",
    "            layout=Layout(width='auto', min_width='200px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        load_form.children += (placeholder_input,)\n",
    "        placeholders[var] = placeholder_input\n",
    "        \n",
    "    output_filename_input = Text(\n",
    "        description='Enter a filename to save the filled in prompt template (e.g. my_prompt):',\n",
    "        layout=Layout(width='auto', min_width='200px'),\n",
    "        style={'description_width': 'initial'})\n",
    "    load_form.children += (output_filename_input,)\n",
    "\n",
    "    render_button = Button(description='Save and Render')\n",
    "    render_warning_output = Output()\n",
    "    \n",
    "    warning_and_buttons_layout = VBox([\n",
    "        render_button,\n",
    "        render_warning_output\n",
    "    ])\n",
    "    \n",
    "    load_form.children += (warning_and_buttons_layout,)\n",
    "\n",
    "    # Apply CSS styling to the form container\n",
    "    load_form.layout.width = '100%'\n",
    "    load_form.layout.min_width = '400px'\n",
    "    load_form.add_class('my-form')\n",
    "    \n",
    "    display(load_form)\n",
    "\n",
    "    def on_render_and_save(button):\n",
    "        \"\"\"Render the template with the provided user input and globally save the rendered text.\"\"\"\n",
    "\n",
    "        rendered_text = render_and_save(button)\n",
    "        if rendered_text is not None:\n",
    "            # Assign the rendered_text to a variable in the global scope using globals()\n",
    "            globals()['rendered_prompt'] = rendered_text\n",
    "    \n",
    "    def render_and_save(button):\n",
    "        \"\"\"Render the template with the provided user input and save the rendered text to a file.\"\"\"\n",
    "\n",
    "        placeholder_values = {var: widget.value for var, widget in placeholders.items()}\n",
    "        rendered_text = render_template(template_name, placeholder_values)\n",
    "        output_filename = output_filename_input.value\n",
    "        \n",
    "        # Remove any existing file extension from the output filename\n",
    "        output_filename = os.path.splitext(output_filename)[0] + '.txt'\n",
    "                \n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            with render_warning_output:\n",
    "                print(f'File \"{output_filename}\" already exists. Do you want to overwrite it?')\n",
    "                overwrite_button = Button(description='Overwrite')\n",
    "                overwrite_button.on_click(lambda _: save_rendered_content(output_path, rendered_text, True))\n",
    "                cancel_button = Button(description='Cancel')\n",
    "                cancel_button.on_click(lambda _: render_warning_output.clear_output())\n",
    "                display(overwrite_button, cancel_button)\n",
    "        else:\n",
    "            save_rendered_content(output_path, rendered_text)\n",
    "        \n",
    "        return rendered_text\n",
    "\n",
    "    render_button.on_click(on_render_and_save)\n",
    "\n",
    "def save_rendered_content(file_path, rendered_text, overwrite=False):\n",
    "    \"\"\"Save the rendered text to the specified file path.\"\"\"\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(rendered_text)\n",
    "    with success_output:\n",
    "        print(f'Rendered text saved as \"{os.path.basename(file_path)}\".')\n",
    "    \n",
    "    # Update the preview output widget with the rendered template\n",
    "    with preview_output:\n",
    "        print('Template Preview:')\n",
    "        print(rendered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_widgets():\n",
    "    \"\"\"Create the widgets used in the form.\"\"\"\n",
    "\n",
    "    global template_dropdown, template_content_input, filename_input, save_button, use_button, preview_button\n",
    "    global save_warning_output, success_output, preview_output\n",
    "\n",
    "    template_dropdown = create_template_dropdown()\n",
    "    template_content_input = create_template_content_input()\n",
    "    filename_input = create_filename_input()\n",
    "    save_button = create_save_button()\n",
    "    use_button = create_use_button()\n",
    "    save_warning_output = Output()\n",
    "    success_output = Output()\n",
    "    preview_output = Output()\n",
    "\n",
    "def create_layout():\n",
    "    \"\"\"Create the main layout of the form.\"\"\"\n",
    "    \n",
    "    input_layout = VBox([\n",
    "        Label(value='Template Manager', style={'font_weight': 'bold', 'font_size': '18px'}),    \n",
    "        Label(value='Select a template to modify. Or create a new one by selecting blank_template and entering your template.'),\n",
    "        template_dropdown,\n",
    "        Label(value='Edit the template content below:'),\n",
    "        template_content_input,\n",
    "        Label(value=\"If you have created a new template or modified an existing one, enter a new name for it here. Skip this step if you're directly using an existing template out-of-the-box.\"),\n",
    "        filename_input,\n",
    "    ])\n",
    "    \n",
    "    save_button_layout = HBox([save_button])\n",
    "    \n",
    "    warning_and_success_layout = VBox([\n",
    "        save_warning_output,\n",
    "        success_output\n",
    "    ])\n",
    "    \n",
    "    separator_layout = HBox([Label(value='─' * 50, style={'font_size': '20px'})])\n",
    "    \n",
    "    use_button_description = Label(value='''Once you have decided on a template, let's use it. Please make sure the template you want is the one currently selected in the top dropdown menu. Once you press the 'Use Template' button, you'll be asked to fill in the relevant variables.''',\n",
    "                                        layout=Layout(width='auto'))\n",
    "    \n",
    "    use_button_layout = HBox([use_button])\n",
    "    \n",
    "    button_layout = VBox([\n",
    "        save_button_layout,\n",
    "        warning_and_success_layout,\n",
    "        separator_layout,\n",
    "        use_button_description,\n",
    "        use_button_layout\n",
    "    ], layout=Layout(margin='20px 0px'))\n",
    "    \n",
    "    output_layout = VBox([\n",
    "        preview_output,\n",
    "    ])\n",
    "    \n",
    "    main_layout = VBox([input_layout, button_layout, output_layout], layout=Layout(width='auto'))\n",
    "    return main_layout\n",
    "\n",
    "def initialize():\n",
    "    create_widgets()\n",
    "    template_dropdown.observe(load_template_content, names='value')\n",
    "    layout = create_layout()\n",
    "    display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe5957da17747629f3a11a4352c6cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='Template Manager', style=LabelStyle(font_size='18px', font_weight='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac017301f124b95a5e0dfd712ce5fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Enter value for \"concept\":', layout=Layout(min_width='200px', width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code below allows you to check you are happy with your prompt. If not, reload the form and fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendered Prompt:\n",
      "Please generate a sentence that embodies the concept of honesty, or the opposite of honesty, choosing either with 50% probability. Only write this sentence and nothing else.\n"
     ]
    }
   ],
   "source": [
    "print(\"Rendered Prompt:\")\n",
    "print(rendered_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below your prompts for generating dataset labels.\n",
    "\n",
    "Instructions\n",
    "\n",
    "- The previous form allows you to generate a dataset of prompts.\n",
    "- The next form allows you to create questions that will label each prompt from the generated set of prompts.\n",
    "- Each generated prompt is sent one by one with the question back through the LLM as a new combined prompt to get the label.\n",
    "- Call a prompt from your generated dataset of prompts P.\n",
    "- Imagine the generated dataset of prompts are either polite or impolite statements e.g.\n",
    "- \"Would you be so kind as to pass the water please.\" or \"Give me the water now.\"\n",
    "- You want to label each prompt as \"polite\" or \"impolite\".\n",
    "- In the following form you will be asked to come up with pairs of \"headings\" and \"labellings\"\n",
    "- A \"heading\" is the name for the column for the labelling in your dataset.\n",
    "- A \"labelling\" is the question you will be asking to label the generated prompt.\n",
    "- In the example below:\n",
    "\n",
    "\n",
    "```\n",
    "prompt, ethical_area, ethical_valence\n",
    "\"Would you be so kind as to pass the water please.\", \"polite\", 1\n",
    "\"Give me the water now.\", \"impolite\", 0\n",
    "```\n",
    "\n",
    "- The headings are \"ethical_area\" and \"ethical_valance\"\n",
    "- The labellings that got us the labels might be:\n",
    "- \"Do you think the start of the response in the following text is polite or impolite? Output only the word \\\"polite\\\" for polite, or \\\"impolite\\\" for impolite in single word response within single quote marks. Here is the text: \"\n",
    "- \"Do you think the start of the response in the following text is polite or impolite? Output only the number 1 for polite, or 0 for impolite. Here is the text: \"\n",
    "- Call a specific heading H and a specific labelling L.\n",
    "- P and L would be passed back to the LLM as L + P e.g.\n",
    "- \"Do you think the start of the response in the following text is polite or impolite? Output only the word \\\"polite\\\" for polite, or \\\"impolite\\\" for impolite in single word response within single quote marks. Here is the text: Give me the water now.\"\n",
    "\n",
    "\n",
    "Details\n",
    "\n",
    "- You may need to experiment a little to get good labelling from the LLM.\n",
    "- It is not certain that the LLM will be able to perform the labelling you are asking for, and if it can it may make mistakes.\n",
    "- You need to check the labels are correct both in the Review section and after the full Dataset Generation section.\n",
    "- You need to generate labels for ethical_area and ethical_valency at a minimum for the way the code currently works.\n",
    "- In the example above, ethical_area always map to the same ethical_valency and vice versa. In other words they are synomyms. They need not be though.\n",
    "- Your label's name and the prompt to generate it should be enclosed in quote marks. \n",
    "- Where we want text based labels, e.g. \"polite\" or \"impolite\", please ask for them with quote marks around them. However, given the way this code is constructed, you need to ask for \\\"polite\\\" or \\\"impolite\\\", not \"polite\" or \"impolite\" - that is, add a backslash \\ before each quote mark. This is because you are already typing within a pair of quote marks. \n",
    "- When asking for a number, do not ask for quote marks around them.\n",
    "- It is a good idea to ask the LLM for the single word or number or whatever else you want so it does not add in unnecessary additional comments such as \"Sure, this sentence is impolite\" etc whcih we do not want as part of our label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "\n",
    "class HeadingLabellingForm(widgets.VBox):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hl_pairs = {}\n",
    "        self.hl_rows = []\n",
    "        \n",
    "        # Directory for saving the dictionary\n",
    "        self.output_dir = '../data/inputs/labels'\n",
    "        \n",
    "        # New explanatory text at the top of the form\n",
    "        self.top_text = widgets.HTML(value=\"\"\"<h3>Heading-Labelling Form</h3>\n",
    "                                     <p>Use this form to load, modify or create heading-labelling schemes.</p>\n",
    "                                     <p>1. To load an existing scheme without modification, select the scheme from the dropdown menu and press the \"Finish Headings and Labellings button\".</p>\n",
    "                                     <p>2. To modify an existing scheme, select the scheme from the dropdown menu, click the \"Add Heading and Labelling\" button for each new pair you want to add, or modify or delate existing pairs, press the \"Finish Headings and Labellings\" button, then save.\n",
    "                                     <p>2. To create a new scheme, click the \"Add Heading and Labelling\" button for each new pair you want to add, or modify or delate as necessary, press the \"Finish Headings and Labellings\" button, then save.\"\"\")\n",
    "        \n",
    "        # Dropdown for selecting an existing H-L file\n",
    "        self.hl_dropdown = widgets.Dropdown(options=self.load_hl_files(), description='Select an H-L file:')\n",
    "        self.hl_dropdown.observe(self.load_hl_file, names='value')\n",
    "        \n",
    "        # Explanatory text\n",
    "        self.explanatory_text = widgets.HTML(value='<p>Click the \"Add Heading and Labelling\" button to add a new heading-labelling pair. You can modify the existing pairs before clicking the \"Finish Headings\" button.</p>')\n",
    "        \n",
    "        # Add Heading and Labelling button\n",
    "        self.add_button = widgets.Button(description='Add Heading and Labelling')\n",
    "        self.add_button.on_click(self.add_hl_pair)\n",
    "        self.add_button.layout.width = '200px'\n",
    "        \n",
    "        # Finish Headings button\n",
    "        self.finish_button = widgets.Button(description='Finish Headings and Labellings')\n",
    "        self.finish_button.on_click(self.finish_headings)\n",
    "        self.finish_button.layout.width = '200px'\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Filename input\n",
    "        self.filename_input = widgets.Text(placeholder='Enter filename to save dictionary')\n",
    "        self.filename_input.layout.width = '300px'\n",
    "        \n",
    "        # Save Dictionary button\n",
    "        self.save_button = widgets.Button(description='Save Dictionary')\n",
    "        self.save_button.on_click(self.save_dictionary)\n",
    "        self.save_button.layout.width = '200px'\n",
    "        \n",
    "        self.warning_output = widgets.Output()\n",
    "        \n",
    "        # Add widgets to the layout\n",
    "        self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]\n",
    "\n",
    "    def load_hl_files(self):\n",
    "        return [os.path.splitext(f)[0] for f in os.listdir(self.output_dir) if f.endswith('.json')]\n",
    "\n",
    "    def load_hl_file(self, change):\n",
    "        hl_filename = change['new'] + '.json'\n",
    "        hl_file_path = os.path.join(self.output_dir, hl_filename)\n",
    "        with open(hl_file_path, 'r') as file:\n",
    "            self.hl_pairs = json.load(file)\n",
    "        \n",
    "        self.hl_rows = []\n",
    "        for heading, labelling in self.hl_pairs.items():\n",
    "            heading_input = widgets.Text(value=heading)\n",
    "            labelling_input = widgets.Text(value=labelling)\n",
    "            labelling_input.layout.width = '100%'\n",
    "            remove_button = widgets.Button(description='Remove')\n",
    "            remove_button.layout.width = '80px'\n",
    "            remove_button.on_click(self.remove_hl_pair)\n",
    "            row = widgets.HBox([heading_input, labelling_input, remove_button])\n",
    "            self.hl_rows.append(row)\n",
    "        \n",
    "        self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, *self.hl_rows, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]\n",
    "\n",
    "    def update_hl_rows(self):\n",
    "        self.hl_rows = []\n",
    "        new_hl_pairs = {}\n",
    "        for heading, labelling in self.hl_pairs.items():\n",
    "            heading_input = widgets.Text(value=heading)\n",
    "            labelling_input = widgets.Text(value=labelling)\n",
    "            labelling_input.layout.width = '100%'\n",
    "            remove_button = widgets.Button(description='Remove')\n",
    "            remove_button.layout.width = '80px'\n",
    "            remove_button.on_click(self.remove_hl_pair)\n",
    "            row = widgets.HBox([heading_input, labelling_input, remove_button])\n",
    "            self.hl_rows.append(row)\n",
    "            new_hl_pairs[heading_input] = labelling_input\n",
    "        self.hl_pairs = new_hl_pairs\n",
    "        self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, *self.hl_rows, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]\n",
    "\n",
    "    def add_hl_pair(self, button):\n",
    "        heading_input = widgets.Text(placeholder='Enter heading key')\n",
    "        labelling_input = widgets.Text(placeholder='Enter labelling')\n",
    "        labelling_input.layout.width = '100%'\n",
    "        remove_button = widgets.Button(description='Remove')\n",
    "        remove_button.layout.width = '80px'\n",
    "        remove_button.on_click(self.remove_hl_pair)\n",
    "        row = widgets.HBox([heading_input, labelling_input, remove_button])\n",
    "        self.hl_rows.append(row)\n",
    "        self.hl_pairs[heading_input] = labelling_input\n",
    "        self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, *self.hl_rows, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]\n",
    "\n",
    "    def finish_headings(self, button):\n",
    "        self.hl_pairs = {heading.value.strip(): labelling.value.strip() for heading, labelling in zip([row.children[0] for row in self.hl_rows], [row.children[1] for row in self.hl_rows]) if heading.value.strip() and labelling.value.strip()}\n",
    "        self.output.clear_output()\n",
    "        with self.output:\n",
    "            display(widgets.HTML(f'<p>Heading-Labelling pairs:</p><pre>{self.hl_pairs}</pre>'))\n",
    "        globals()['hl_pairs'] = self.hl_pairs\n",
    "\n",
    "    def save_dictionary(self, button):\n",
    "        filename = self.filename_input.value.strip()\n",
    "        if not filename:\n",
    "            self.warning_output.clear_output()\n",
    "            with self.warning_output:\n",
    "                print(\"Please enter a filename.\")\n",
    "            return\n",
    "        \n",
    "        if not filename.endswith('.json'):\n",
    "            filename += '.json'\n",
    "        \n",
    "        file_path = os.path.join(self.output_dir, filename)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            self.warning_output.clear_output()\n",
    "            with self.warning_output:\n",
    "                print(f'File \"{filename}\" already exists. Do you want to overwrite it?')\n",
    "                overwrite_button = widgets.Button(description='Overwrite')\n",
    "                overwrite_button.on_click(lambda _: self.save_dictionary_to_file(file_path))\n",
    "                cancel_button = widgets.Button(description='Cancel')\n",
    "                cancel_button.on_click(lambda _: self.warning_output.clear_output())\n",
    "                display(widgets.HBox([overwrite_button, cancel_button]))\n",
    "        else:\n",
    "            self.save_dictionary_to_file(file_path)\n",
    "            \n",
    "            # Refresh the dropdown options and select the newly saved file\n",
    "            self.hl_dropdown.options = self.load_hl_files()\n",
    "            self.hl_dropdown.value = os.path.splitext(filename)[0]\n",
    "\n",
    "    def save_dictionary_to_file(self, file_path):\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(self.hl_pairs, file)\n",
    "        \n",
    "        self.warning_output.clear_output()\n",
    "        with self.output:\n",
    "            print(f'Dictionary saved as \"{file_path}\".')\n",
    "\n",
    "    def remove_hl_pair(self, button):\n",
    "        row = None\n",
    "        for r in self.hl_rows:\n",
    "            if button in r.children:\n",
    "                row = r\n",
    "                break\n",
    "        if row:\n",
    "            self.hl_rows.remove(row)\n",
    "            heading_input = row.children[0]\n",
    "            del self.hl_pairs[heading_input]\n",
    "            row.close()\n",
    "            self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, *self.hl_rows, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f92c97fff949e6a6d500226f08e3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HeadingLabellingForm(children=(HTML(value='<h3>Heading-Labelling Form</h3>\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_form = HeadingLabellingForm()\n",
    "display(qa_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-L Pairs:\n",
      "{'ethical_area': '\"Do you think the start of the response in the following text is honest or dishonest? Output only the word \\\\\"honest\\\\\" for honest, or \\\\\"dishonest\\\\\" for dishonest in single word response within single quote marks. Here is the text: \"', 'ethical_valence': '\"Do you think the start of the response in the following text is honestor dishonest? Output only the number 1 for honest, or 0 for dishonest. Here is the text: \"'}\n"
     ]
    }
   ],
   "source": [
    "print(\"H-L Pairs:\")\n",
    "print(hl_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "You do not need to alter the code in any of the cells from here or on. What you do need to do is as follows: after running the code to the end of this section, just before the Dataset Generation Section, check that the kinds of prompts that are being generated for the new dataset of prompts are as you expected, and that any labelling of the data that is being done looks correct. This is to save you wasting time and money by avoiding generating the whole dataset but then not liking the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! CHECK YOUR DATASET SAMPLE HERE BEFORE CONTINUING!!!\n",
    "\n",
    "If you are happy with the results, continue, if not, go back to the start of the Inputs section and work through to this point again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/inputs/datasets/honesty\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.join(\"../data/inputs/datasets\", filestem)\n",
    " \n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "    print(f\"Directory created: {dataset_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset by calling the OpenAI API\n",
    "def generate_dataset_from_prompt(prompt,\n",
    "                                 generated_dataset_file_path,\n",
    "                                 model,\n",
    "                                 log_file_path,\n",
    "                                 i):\n",
    "    completion = client.chat.completions.create(\n",
    "            **{\n",
    "                \"model\": model,\n",
    "                \"temperature\": temperature,\n",
    "                \"seed\": i,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    completion_words = completion.choices[0].message.content.strip()\n",
    "\n",
    "    # cleaned_completion = completion.choices[0].message.content.strip()[3:-3]\n",
    "    print(\" \")\n",
    "    print(completion_words)\n",
    "    print(\" \")\n",
    "\n",
    "    # Open a file in write mode ('w') and save the CSV data\n",
    "    with open(generated_dataset_file_path+\"_\"+str(i)+\".txt\", 'w', newline='', encoding='utf-8') as file:\n",
    "        file.write(completion_words)\n",
    "\n",
    "    num_words_in_prompt = count_words_in_string(prompt)\n",
    "    num_words_in_completion = count_words_in_string(completion_words)\n",
    "    total_words = num_words_in_prompt + num_words_in_completion\n",
    "\n",
    "    num_tokens_in_prompt = completion.usage.prompt_tokens\n",
    "    num_tokens_in_completion = completion.usage.completion_tokens\n",
    "    total_tokens = num_tokens_in_prompt + num_tokens_in_completion\n",
    "\n",
    "    prompt_cost = num_tokens_in_prompt*0.01/1000\n",
    "    completion_cost = num_tokens_in_completion*0.03/1000\n",
    "    total_cost = prompt_cost + completion_cost\n",
    "    \n",
    "    tokens_per_prompt_word = num_words_in_prompt/num_tokens_in_prompt\n",
    "    tokens_per_completion_word = num_words_in_completion/num_tokens_in_completion\n",
    "\n",
    "    log = {\n",
    "            \"num_words_in_prompt\": num_words_in_prompt,\n",
    "            \"num_words_in_completion\": num_words_in_completion,\n",
    "            \"total_words\": total_words,\n",
    "            \"num_tokens_in_prompt\": num_tokens_in_prompt,\n",
    "            \"num_tokens_in_completion\": num_tokens_in_completion,\n",
    "            \"total_tokens\": total_tokens,\n",
    "            \"prompt_cost\": prompt_cost,\n",
    "            \"completion_cost\": completion_cost,\n",
    "            \"total_cost\": total_cost,\n",
    "            \"tokens_per_prompt_word\": tokens_per_prompt_word,\n",
    "            \"tokens_per_completion_word\": tokens_per_completion_word\n",
    "\n",
    "    }\n",
    "\n",
    "    for k, v in log.items():\n",
    "        print(k, v)\n",
    "    print(\" \")\n",
    "\n",
    "    with open(log_file_path+\"_\"+str(i)+\".txt\", 'w') as file:\n",
    "        file.write(json.dumps(log, indent=4))\n",
    "\n",
    "def count_words_in_string(input_string):\n",
    "    words = input_string.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Repeat the following instruction 10 times, always generating a unique answer to the instruction. Begin instruction: Please generate a sentence that embodies the concept of honesty, or the opposite of honesty, choosing either with 50% probability. Only write this sentence and nothing else. End instruction. Put the result of each instruction within a pair quote marks on a new line as if each was the row of a single column csv and include no other text.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"Repeat the following instruction 10 times, always generating a unique answer to the instruction. Begin instruction: {rendered_prompt} End instruction. Put the result of each instruction within a pair quote marks on a new line as if each was the row of a single column csv and include no other text.\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "\"Truthfulness is the compass that guides us through the fog of deception.\"\n",
      "\"Lies are the chains that bind us to a life of shadows.\"\n",
      "\"Honesty is not just a policy, but the very foundation upon which trust is built.\"\n",
      "\"Deception is a game played with the fragile cards of trust.\"\n",
      "\"Speaking the truth is like releasing a bird into the sky, free and boundless.\"\n",
      "\"Crafting a lie is like weaving a net in which eventually we ourselves will be caught.\"\n",
      "\"True honesty shines like a beacon, guiding us toward integrity.\"\n",
      "\"In the theater of deceit, every actor wears a mask of falsehood.\"\n",
      "\"An honest heart is a kingdom's strongest fortress.\"\n",
      "\"Fabrications are the bricks used to build a mansion of illusions.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 121\n",
      "total_words 197\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 151\n",
      "total_tokens 256\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.00453\n",
      "total_cost 0.00558\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.8013245033112583\n",
      " \n",
      "The code took 8.056833505630493 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "# Generate the sample dataset\n",
    "\n",
    "# First save the prompt as a text file\n",
    "with open(dataset_dir+\"/prompt.txt\", 'w', newline='', encoding='utf-8') as file:\n",
    "    file.write(prompt)\n",
    "\n",
    "# Define the file path for the generated dataset\n",
    "generated_dataset_file_path = os.path.join(dataset_dir, f\"{filestem}\")\n",
    "\n",
    "# Define the log file path\n",
    "log_file_path = os.path.join(dataset_dir, \"log\")\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = math.ceil(total_num_examples/num_examples_per_request)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate sample dataset\n",
    "generate_dataset_from_prompt(prompt, generated_dataset_file_path, model, log_file_path, 0)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The code took {elapsed_time} seconds to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Iteration:  0\n",
      " \n",
      "\"True honesty shines brightest when spoken without expectation of reward.\"  \n",
      "\"Fabrications often crumble under the weight of truth.\"  \n",
      "\"In every lie, there's a silent plea for forgiveness.\"  \n",
      "\"A candid remark opens the door to genuine relationships.\"  \n",
      "\"Deception is the shadow cast by the absence of truth.\"  \n",
      "\"Sincerity is a bridge built with the bricks of truth.\"  \n",
      "\"With every falsehood, trust erodes like a cliff against the sea.\"  \n",
      "\"Honesty is the embroidery of the soul's purest thoughts.\"  \n",
      "\"Lies are the temporary shelters of the cowardly.\"  \n",
      "\"An honest heart speaks a language understood by all.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 93\n",
      "total_words 169\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 132\n",
      "total_tokens 237\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.00396\n",
      "total_cost 0.0050100000000000006\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.7045454545454546\n",
      " \n",
      "1\n",
      "Iteration:  1\n",
      " \n",
      "\"Being truthful may not always be easy, but it is the most respectful path.\"\n",
      "\"Lies are shadows, casting doubt on even our brightest truths.\"\n",
      "\"An honest heart reflects a life of integrity, leaving no room for deceit.\"\n",
      "\"In the realm of deceit, truth is often cloaked in illusions.\"\n",
      "\"Honesty plants seeds of trust that can grow into unbreakable bonds.\"\n",
      "\"A lie is a thief, stealing the trust that was once freely given.\"\n",
      "\"Truthfulness is the foundation upon which all virtues rest.\"\n",
      "\"Falseness is a shaky foundation that crumbles under the slightest scrutiny.\"\n",
      "\"To speak honestly is to lay bare the soul, vulnerable but free.\"\n",
      "\"Deception is a labyrinth with no exit, trapping both the liar and the truth.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 118\n",
      "total_words 194\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 150\n",
      "total_tokens 255\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.0045\n",
      "total_cost 0.005549999999999999\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.7866666666666666\n",
      " \n",
      "2\n",
      "Iteration:  2\n",
      " \n",
      "\"Truthfulness is the seed from which trust grows.\"\n",
      "\"Dishonesty is a shadow that darkens even the brightest truth.\"\n",
      "\"An honest heart speaks without deceit.\"\n",
      "\"Lies are the bricks with which a fragile reality is built.\"\n",
      "\"To be honest is to be the voice of clarity in a world muddled by lies.\"\n",
      "\"Deception is a twisted path that leads nowhere good.\"\n",
      "\"Speaking truthfully is like shining a light in the darkness of deception.\"\n",
      "\"Fibbing is the art of painting reality with the colors of falsehood.\"\n",
      "\"Authenticity is a rare jewel in the fabric of society.\"\n",
      "\"Fabricating stories is like weaving a tapestry of illusions.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 103\n",
      "total_words 179\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 134\n",
      "total_tokens 239\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.004019999999999999\n",
      "total_cost 0.00507\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.7686567164179104\n",
      " \n",
      "3\n",
      "Iteration:  3\n",
      " \n",
      "\"Truthfulness is the first pillar upon which a robust moral character is built.\"\n",
      "\"Dishonesty is a dark cloud that obscures the light of integrity.\"\n",
      "\"Honesty paves the path with golden bricks of trust and reliability.\"\n",
      "\"Lies are the shadows that stretch between small mistruths and egregious deceit.\"\n",
      "\"An honest heart speaks volumes more than a mouthful of lies.\"\n",
      "\"In the economy of morals, honesty is the currency of the highest value.\"\n",
      "\"Deception is like a tangled web; the more one lies, the harder it is to escape.\"\n",
      "\"To live honestly is to allow your soul to breathe freely and deeply.\"\n",
      "\"The fabric of society is stitched together with threads of truth and honesty.\"\n",
      "\"Choosing dishonesty is building a house with sand; it may stand temporarily but will eventually collapse.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 129\n",
      "total_words 205\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 161\n",
      "total_tokens 266\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.00483\n",
      "total_cost 0.00588\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.8012422360248447\n",
      " \n",
      "4\n",
      "Iteration:  4\n",
      " \n",
      "\"Truthfulness is the cornerstone of trust in any relationship.\"\n",
      "\"Sometimes, people weave intricate lies when honesty seems too daunting.\"\n",
      "\"An honest heart reflects a clear conscience like a mirror reflects a face.\"\n",
      "\"In a tapestry of deception, every thread counts towards the grand design of illusion.\"\n",
      "\"Choosing honesty is like planting a seed that grows into a tree of integrity.\"\n",
      "\"Lies are like a virus, spreading and mutating until the truth is unrecognizable.\"\n",
      "\"Honesty is the first chapter in the book of wisdom.\"\n",
      "\"Fabricating stories can sometimes lead the storyteller to believe in their own illusions.\"\n",
      "\"To speak the truth is to speak with love; honesty nurtures understanding and connection.\"\n",
      "\"Deceit leaves a trail, a shadow that follows closely, growing with each step away from the light.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 127\n",
      "total_words 203\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 161\n",
      "total_tokens 266\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.00483\n",
      "total_cost 0.00588\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.7888198757763976\n",
      " \n",
      "5\n",
      "Iteration:  5\n",
      " \n",
      "\"Truthfulness is the very cornerstone of trust.\"\n",
      "\"Honesty illuminates the darkest of secrets with a single ray of light.\"\n",
      "\"Deception is a twisted path leading nowhere but to more deceit.\"\n",
      "\"An honest heart speaks a language understood universally.\"\n",
      "\"Lies are like spiders, spinning webs to trap the unwary.\"\n",
      "\"To speak the truth is to plant the seed of integrity.\"\n",
      "\"A lie once told is forever in search of shadows to hide.\"\n",
      "\"Living with honesty is like sailing on calm waters.\"\n",
      "\"Falsehoods are the shadows that fear the light of truth.\"\n",
      "\"In the realm of honesty, every word weighs its worth in gold.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 102\n",
      "total_words 178\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 128\n",
      "total_tokens 233\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.0038399999999999997\n",
      "total_cost 0.00489\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.796875\n",
      " \n",
      "6\n",
      "Iteration:  6\n",
      " \n",
      "\"Truthfulness is the seed from which trust grows.\"  \n",
      "\"Lies are the shadows where mistrust festers.\"  \n",
      "\"Honesty is the bridge that connects hearts with integrity.\"  \n",
      "\"Deception is a maze with no exits, only deeper entanglements.\"  \n",
      "\"Speaking truth is like sailing in clear waters, navigating becomes effortless.\"  \n",
      "\"To lie is to weave a tapestry with threads of deceit, destined to unravel.\"  \n",
      "\"An honest word is a light in the darkness, guiding the way forward.\"  \n",
      "\"A dishonest tongue can poison a well of a thousand truths.\"  \n",
      "\"Transparency in one's words is akin to sunlight; it disinfects doubts.\"  \n",
      "\"Fabrications are the fog that blurs the landscape of reality.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 104\n",
      "total_words 180\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 150\n",
      "total_tokens 255\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.0045\n",
      "total_cost 0.005549999999999999\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.6933333333333334\n",
      " \n",
      "7\n",
      "Iteration:  7\n",
      " \n",
      "\"Honesty is the key that unlocks the door to trust in any relationship.\"\n",
      "\"While the truth can set you free, a lie can trap you in a cage of your own making.\"\n",
      "\"An honest answer is a sign of true friendship.\"\n",
      "\"In the deceitful shadows of half-truths, true intentions often hide.\"\n",
      "\"Honesty plants the seeds of integrity, which bloom into the flowers of lasting respect.\"\n",
      "\"Every lie weaves a tangled web, ensnaring its creator more with every thread.\"\n",
      "\"To speak with honesty is to build a bridge of reliability over the river of doubt.\"\n",
      "\"Lies are like snowballs down a hill; they grow bigger and faster until they cause an avalanche.\"\n",
      "\"Being honest may not always win you friends, but it will always earn you the right ones.\"\n",
      "\"The art of deception is a fragile craft where the pieces never quite fit together.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 143\n",
      "total_words 219\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 175\n",
      "total_tokens 280\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.00525\n",
      "total_cost 0.0063\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.8171428571428572\n",
      " \n",
      "8\n",
      "Iteration:  8\n",
      " \n",
      "\"Truthfulness is the seed from which trust grows.\"\n",
      "\"Lies are the shadows where trust withers.\"\n",
      "\"Honesty is the music that harmonizes the chorus of humanity.\"\n",
      "\"Deception is the fog that blurs the path of integrity.\"\n",
      "\"Being honest is like holding a torch in the darkness of deceit.\"\n",
      "\"A lie is a crack in the mirror of one's character.\"\n",
      "\"To speak honestly is to paint reality in its true colors.\"\n",
      "\"Fabrications are the bricks building walls between hearts.\"\n",
      "\"An honest heart is a beacon in the tempest of life.\"\n",
      "\"A falsehood is a gust that extinguishes the lamp of truth.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 99\n",
      "total_words 175\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 126\n",
      "total_tokens 231\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.00378\n",
      "total_cost 0.00483\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.7857142857142857\n",
      " \n",
      "9\n",
      "Iteration:  9\n",
      " \n",
      "\"Truthfulness is the foundation upon which trust is built.\"\n",
      "\"Honesty is the best policy, for it breeds transparency and trust.\"\n",
      "\"To lie is to weave a tangled web that ensnares not just the liar but also those around them.\"\n",
      "\"Deception is a tool for the weak, used to manipulate and control.\"\n",
      "\"A sincere heart never needs to hide behind falsehoods or deceit.\"\n",
      "\"Betrayal begins with a single act of dishonesty, growing like a cancerous cell.\"\n",
      "\"Being truthful may not always be easy, but it is always the most honorable path.\"\n",
      "\"Lies are the shadows where trust fears to tread.\"\n",
      "\"Integrity is choosing honesty over convenience, even when no one is watching.\"\n",
      "\"Dishonesty is a fleeting victory that ultimately leads to a permanent loss.\"\n",
      " \n",
      "num_words_in_prompt 76\n",
      "num_words_in_completion 123\n",
      "total_words 199\n",
      "num_tokens_in_prompt 105\n",
      "num_tokens_in_completion 159\n",
      "total_tokens 264\n",
      "prompt_cost 0.0010500000000000002\n",
      "completion_cost 0.00477\n",
      "total_cost 0.0058200000000000005\n",
      "tokens_per_prompt_word 0.7238095238095238\n",
      "tokens_per_completion_word 0.7735849056603774\n",
      " \n",
      "The code took 97.62365961074829 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "# Define the log file path\n",
    "log_file_path = os.path.join(dataset_dir, \"log\")\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = math.ceil(total_num_examples/num_examples_per_request)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate the dataset\n",
    "for i in range(num_iterations):\n",
    "    print(\"Iteration: \", i)\n",
    "    generate_dataset_from_prompt(prompt, generated_dataset_file_path, model, log_file_path, i+1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The code took {elapsed_time} seconds to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at random sample of dataset - useful for getting a sense if the data has been labelled correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['honesty_0.txt', 'honesty_4.txt', 'honesty_6.txt', 'honesty_3.txt', 'honesty_8.txt', 'honesty_5.txt', 'honesty_7.txt', 'honesty_1.txt', 'honesty_10.txt', 'honesty_2.txt', 'honesty_9.txt']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all the files you want to process\n",
    "# Makes sure they all have the same prompt context\n",
    "# eg won;t mix up honest with justice etc\n",
    "files = [f for f in os.listdir(dataset_dir) \n",
    "                      if f.endswith('.txt') and 'honesty' in f.lower()]\n",
    "\n",
    "print(files)\n",
    "\n",
    "# Define the regular expression pattern\n",
    "# Get lines that start with a quote,\n",
    "# then have any number of characters,\n",
    "# then end with a quote and possibly comma\n",
    "# We're trying to find all valid CSV lines\n",
    "pattern = r'^\\\".*\\\",?[\\r\\n]*'\n",
    "\n",
    "# Open the master CSV file\n",
    "with open(os.path.join(dataset_dir, filestem+\".txt\"), \"a\") as master:\n",
    "    # Loop over the files\n",
    "    for file in files:\n",
    "        # Open the current file and read its contents\n",
    "        with open(os.path.join(dataset_dir, file), 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Use the re.findall function to find all matches in the content\n",
    "        matches = re.findall(pattern, content, re.MULTILINE)        \n",
    "\n",
    "        # Loop over the matches\n",
    "        for match in matches:\n",
    "            \n",
    "            # Remove any trailing commas and newline characters\n",
    "            match_cleaned = match.rstrip(',\\r\\n')\n",
    "            \n",
    "            # Append the match to the master CSV file\n",
    "            master.write(match_cleaned + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add optional columns for classification\n",
    "\n",
    "The columns added here work with the defaults currently hardcoded into the data analysis\n",
    "This hardcoding will be resolved soon for more flexibility.\n",
    "\n",
    "I show examples of using am LLM to auto-label and a way to label if you knw in advance which rows are of which kind of label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of labelling using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "                **{\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "input_file_path = combined_dataset_file_path\n",
    "output_file_path = os.path.join(generated_dataset_dir, prompt_context+\"_combined_dataset_ethical_area.csv\")\n",
    "\n",
    "\n",
    "with open(input_file_path, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    \n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    # Add a header\n",
    "    writer.writerow([\"Prompt\", \"Ethical Area\"])\n",
    "    \n",
    "    for row in reader:\n",
    "        # Assuming each row contains a single column with your text\n",
    "        question = row[0]  # Adjust this if your structure is different\n",
    "        # Here you define the question you want to ask about each row\n",
    "        prompt = f\"Do you think the start of the response in '{question}' is good or bad? Output only the word \\\"Good\\\" for good, or \\\"Bad\\\" for bad in single word response within single quote marks.\"\n",
    "        response = ask_openai(prompt)\n",
    "        # Add the OpenAI response to the row\n",
    "        row.append(response)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of labelling programatically without LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we might not need to query the API for kind of lebelling\n",
    "# Eg if we know the questions always go good, bad, good, bad, good etc\n",
    "\n",
    "input_file_path = os.path.join(generated_dataset_dir, prompt_context+\"_combined_dataset_ethical_area.csv\")\n",
    "output_file_path = os.path.join(generated_dataset_dir, prompt_context+\"_combined_dataset_fully_labelled.csv\")\n",
    "\n",
    "with open(input_file_path, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    \n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    # If your CSV has a header and you want to keep it, read and write it first\n",
    "    # This also allows you to add a new column name to the header\n",
    "    header = next(reader)\n",
    "    header.append(\"Positive\")  # Add your new column name here\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Enumerate adds a counter to an iterable and returns it (the enumerate object).\n",
    "    for index, row in enumerate(reader, start=1):  # Start counting from 1\n",
    "        if index % 2 == 0:  # Check if the row number is even\n",
    "            row.append(0)\n",
    "        else:\n",
    "            row.append(1)\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
