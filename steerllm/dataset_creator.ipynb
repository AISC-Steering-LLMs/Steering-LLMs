{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo:\n",
    "\n",
    "# Have working on Colab ON HOLD\n",
    "\n",
    "# General usability. PROGRESS\n",
    "\n",
    "# General form layout imprvements. PROGRESS\n",
    "\n",
    "# Directory of all pre-existing labels - biggest change?\n",
    "\n",
    "# Make \"Here is the text: \" hardcoded at the end of the users labelling text/\n",
    "\n",
    "# Backslashes necessary in labelling promptd?\n",
    "\n",
    "# Form for initial stuff like model, temperature etc? DONE\n",
    "\n",
    "# Make sure the instructions are clear and concise and make sense given the updates PROGRESS\n",
    "\n",
    "# Sort the placeholder ordering to reflect the order in the template\n",
    "\n",
    "# Put all background code in a DataGenerator class\n",
    "\n",
    "# General code quality\n",
    "# - probably some repeated code between forms that could be refactored\n",
    "# - much of the form code stitched together from LLM generated code for fast prototyping\n",
    "# --- Is it all necessary?\n",
    "# --- Can it be improved?\n",
    "# --- Does it make sense?\n",
    "# TODO Aayush to Matthew: It makes sense to do this, though I'd say after we get the usability stuff done? (forms, usability improvements, directory of labels etc.). Since this is mainly a backend improvement, and the notebook users won't care.\n",
    "\n",
    "# Don't allow saving as .csv.json in labelling form DONE (solved using UX)\n",
    "\n",
    "# Track cost of label generation\n",
    "\n",
    "# Prompt novelty\n",
    "# --- random seed but record seeds\n",
    "# --- length\n",
    "# --- Sample from top 5?\n",
    "# --- higher shot in k-shot\n",
    "# --- bigger model - more expensive\n",
    "\n",
    "# Pick up from where we left off of API call fails\n",
    "# Do you loose everything if you stop the API call?\n",
    "# TODO: Aayush to Matthew: How important of a problem is this to solve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to use a prompt given to some LLM (\"LLM A\") to generate a dataset of different prompts to be fed to some other LLM (\"LLM B\" - potentially the same as \"LLM A\") for which you have access to the weights. This dataset of prompts will be used to create a \"representation vector\" of a property or concept for LLM B in order to \"steer\" LLM B to have more of that property or concept in its outputs. This Notebook does not cover the creation of representations or steering, only the the creation of a dataset of prompts.\n",
    "\n",
    "The kinds of prompts you want to generate should be about the property or concept you want to steer the LLM towards, not necessary literally mentioning it - e.g. prompts about politeness do not necessarily need to have the word polite in them. Part of the point of dataset creation is to explore which kinds of generated prompts yield good representations.\n",
    "\n",
    "The Notebook works as follows:\n",
    "\n",
    "- The Setup section loads Python libraries needed to run the code. You do not need to change anything here.\n",
    "- The Inputs section is where you define the prompt you will use to generate your dataset of prompts. Instructions on how to do this are given. This is the only section of the notebook where you will need to change anything.\n",
    "- The Review section then generates a small example dataset of prompts and shows them to you. If you like them, continue on to the end of the Notebook.\n",
    "- If you do not like them, please go back to the Inputs section to refine your prompt to generate your dataset of prompts.\n",
    "- The Dataset Generation section completes the dataset generation.\n",
    "- The View Dataset section loads your generated dataset for inspection.\n",
    "- Your dataset will be stored in /data/inputs/name_of_your_dataset/dataset if you want to use it later.\n",
    "\n",
    "The datasets will be generated in CSV format and should have the following form, where the first line is the column headings and subsequent lines are for example prompts. The columns ethical_area and ethical_valence are two different labels (classifications) of the prompt. The Notebook will help you generate these labels. This example is for \"politeness\" prompts:\n",
    "\n",
    "```\n",
    "prompt, ethical_area, ethical_valence\n",
    "\"Would you be so kind as to pass the water please.\", \"polite\", 1\n",
    "\"Give me the water now.\", \"impolite\", 0\n",
    "```\n",
    "\n",
    "If this is too restrictive, you will be able to create other columns and the notebook will ask you about that too.\n",
    "\n",
    "Note that where we have text, such as for the prompt or ethical_area, we want it enclosed in quote marks. Lone numbers do not need this.\n",
    "\n",
    "If there is something unusual you want to do that the current notebook does not permist, please ask, or feel free to try adding code for it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup (just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from IPython import get_ipython\n",
    "from IPython.display import display, HTML, clear_output\n",
    "from ipywidgets import (\n",
    "    Button,\n",
    "    Checkbox,\n",
    "    Dropdown,\n",
    "    FloatText,\n",
    "    HBox,\n",
    "    IntText,\n",
    "    Label,\n",
    "    Layout,\n",
    "    Output,\n",
    "    SelectMultiple,\n",
    "    Text,\n",
    "    Textarea,\n",
    "    VBox,\n",
    "    interactive,\n",
    "    interact,\n",
    "    interact_manual,\n",
    "    fixed,\n",
    "    widgets,\n",
    ")\n",
    "from jinja2 import Environment, FileSystemLoader, meta\n",
    "from hydra import initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.experimental import compose\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf2c8c35471f4769a1ec5130a9f43e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='hello', description='Enter your OpenAI API key:', style=TextStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fa9efe2d7d4be2a8d3c041cc393cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='OpenAI Model:', index=1, options=('gpt-4-0125-preview', 'gpt-4', 'gpt-3.5-turbo'), style…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8994f6f9916a42a7bf6a5e05316d147a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=1.0, continuous_update=False, description='Temperature:', max=2.0, readout_format='.1f', sty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac85694f3b541a0b8572d0fdf03d915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='justice', description='Filename (without extension):', style=TextStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae6009ad80446e0ae905825b1a23477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=100, description='Total Number of Examples:', style=DescriptionStyle(description_width='initial'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6992bfb8d6fd44ceab52436b13358c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntText(value=100, description='Examples per Request:', style=DescriptionStyle(description_width='initial'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ded26dd672c441878a78e35b76cf7b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Button(description='Submit', style=ButtonStyle()), Button(description='Reset', style=ButtonStyl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OpenAI API Key\n",
    "api_key_input = widgets.Text(\n",
    "    value=os.environ.get(\"OPENAI_API_KEY\", \"\"),\n",
    "    description='Enter your OpenAI API key:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "def save_api_key(api_key):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    print(\"API key saved to environment variables.\")\n",
    "\n",
    "api_key_button = widgets.Button(description=\"Save API Key\")\n",
    "api_key_button.on_click(lambda _: save_api_key(api_key_input.value))\n",
    "api_key_box = widgets.VBox([api_key_input, api_key_button])\n",
    "\n",
    "# Model Selection\n",
    "model_options = ['gpt-4-0125-preview', 'gpt-4', 'gpt-3.5-turbo']\n",
    "model_dropdown = widgets.Dropdown(\n",
    "    options=model_options,\n",
    "    value='gpt-4',\n",
    "    description='OpenAI Model:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Temperature\n",
    "temperature_input = widgets.FloatSlider(\n",
    "    value=1.0,\n",
    "    min=0.0,\n",
    "    max=2.0,\n",
    "    step=0.1,\n",
    "    description='Temperature:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Filename\n",
    "filename_input = widgets.Text(\n",
    "    value='justice',\n",
    "    description='Filename (without extension):',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Total Number of Examples\n",
    "total_examples_input = widgets.IntText(\n",
    "    value=100,\n",
    "    description='Total Number of Examples:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Number of Examples per Request\n",
    "examples_per_request_input = widgets.IntText(\n",
    "    value=100,\n",
    "    description='Examples per Request:',\n",
    "    disabled=False,\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Display the widgets\n",
    "display(api_key_box)\n",
    "display(model_dropdown)\n",
    "display(temperature_input)\n",
    "display(filename_input)\n",
    "display(total_examples_input)\n",
    "display(examples_per_request_input)\n",
    "\n",
    "# Retrieve the values\n",
    "def get_inputs():\n",
    "    client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "    model = model_dropdown.value\n",
    "    temperature = temperature_input.value\n",
    "    filestem = filename_input.value   \n",
    "    total_num_examples = total_examples_input.value\n",
    "    num_examples_per_request = examples_per_request_input.value\n",
    "    \n",
    "    print(f\"OpenAI Model: {model}\")\n",
    "    print(f\"Temperature: {temperature}\")\n",
    "    print(f\"Filename: {filestem}.csv\")\n",
    "    print(f\"Total Number of Examples: {total_num_examples}\")\n",
    "    print(f\"Examples per Request: {num_examples_per_request}\")\n",
    "\n",
    "# Reset the values to default\n",
    "def reset_values():\n",
    "    model_dropdown.value = 'gpt-4'\n",
    "    temperature_input.value = 1.0\n",
    "    filename_input.value = 'justice'\n",
    "    total_examples_input.value = 100\n",
    "    examples_per_request_input.value = total_examples_input.value\n",
    "    print(\"Values reset to default.\")\n",
    "\n",
    "submit_button = widgets.Button(description=\"Submit\")\n",
    "submit_button.on_click(lambda _: get_inputs())\n",
    "\n",
    "reset_button = widgets.Button(description=\"Reset\")\n",
    "reset_button.on_click(lambda _: reset_values())\n",
    "\n",
    "button_box = widgets.HBox([submit_button, reset_button])\n",
    "display(button_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hints\n",
    "\n",
    "**OpenAI Api Key**\n",
    "- Get an API key [here](https://auth0.openai.com/u/signup/identifier?state=hKFo2SA1REJ3dGFZVTllNHFvYUFkY2RrWEJpUUVMUWxvel91VqFur3VuaXZlcnNhbC1sb2dpbqN0aWTZIFg1Z2NKOU9hUk4yYUFmWGxyTHlscmtNTmMxbDF5dWZTo2NpZNkgRFJpdnNubTJNdTQyVDNLT3BxZHR3QjNOWXZpSFl6d0Q).\n",
    "- You will need to put some token amount of money on to use gpt-4-0125-preview. It's something like $1. Might be $10.\n",
    "\n",
    "**OpenAI Model**\n",
    "- See [here](https://platform.openai.com/docs/models/) for the list of models: \n",
    "\n",
    "**Temperature**\n",
    "- Lower values for temperature result in more consistent outputs (e.g. 0.2), while higher values generate more diverse and creative results (e.g. 1.0)\n",
    "- If your generated sentences are too similar/boring, try increasing the number. Go the other way if too wacky.\n",
    "- More details [here](https://platform.openai.com/docs/guides/text-generation/how-should-i-set-the-temperature-parameter)\n",
    "\n",
    "**Filename**\n",
    "- Saves the dataset to a file with this name.\n",
    "- Try to give it a specific name e.g. \"honesty_v2.csv\" or \"honesty_pairs_v2.csv\", something that will help you remember what it is especially if you are experimenting with variations.\n",
    "- Giving it the same name as an existing dataset will currently overwrite the existing dataset. TODO: Resolve this.\n",
    "\n",
    "**Total Number of Examples**\n",
    "- This is the total number of prompts you want to generate in your dataset of prompts.\n",
    "- If you want to generate x prompts in total, put x here.\n",
    "- What is the max number of examples one should put here?\n",
    "\n",
    "**Number of Examples per request**\n",
    "- TODO: @Matthew should we get rid of this variable since Rasmus wants everything in one batch, or is there still usefulness to it?\n",
    "- This is the number of prompt examples that are generated per request to the model.\n",
    "- The reason we have this is because the LLM has a limit on the number of words it can process in one request. If you put a number that is too high here, you will not get the number of prompts you want.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Kept this text just in case for now.\n",
    "\n",
    "Enter below the number of examples per request. This is the number of prompt examples you want to generate in one request to the LLM.\n",
    "\n",
    "- This is different from the total_num_examples variable you entered above.\n",
    "- The reason we have this is because the LLM has a limit on the number of tokens it can process in one request. If you put a number that is too high here, you will not get the number of prompts you want.\n",
    "- The number of tokens for gpt-4-0125-preview is 128,000 based on details given here: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo.\n",
    "- From a quick internet search, I think this model uses about 1.3 tokens per word. So you might have about 4096/1.3 = 98,461 words to play with if using this model. Remember, the number of tokens or words includes those in the prompt.\n",
    "- This should be more than enough to generate your entire dataset in one go, so you could try setting num_examples_per_request to the same number as total_num_examples. One reason to err on slightly fewer examples is that bigger responses from OpenAI take longer to generate. If you lose your internet connection before generation has ended, you lose your entire generated dataset. If you generate the data in small batches, you will have a partially complete dataset up until the batch that fails.\n",
    "- This Notebook will make sure that the total number of examples you want to generate as defined in total_num_examples are generated, but it will make multiple requests to the LLM. Eg if you made total_num_examples = 100 and num_examples_per_request = 5, then this code will automatically make 100/5 = 20 requests to the LLM to generate the 100 examples you want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Template Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Example Template:\n",
    "> *Please generate a sentence that embodies the concept of {{concept}}, or the opposite of {{concept}} in the context of {{context}}, choosing either with 50% probability. Only write this sentence and nothing else.*\n",
    "\n",
    "What is a template?\n",
    "- A generic prompt stucture.\n",
    "- Any variable/placeholder you might want to pass to your template should be include within a pair of braces like so: {{ your_variable_name }}\n",
    "- You want to use placeholders where you might want to switch out different parts of the prompt. E.g. you might write {{concept}} instead of politeness or justice or what have you so that you can decide later what to add.\n",
    "- You will be given the opportunity to fill in placeholders at the end of this form.\n",
    "- You should write your templates as if you expect only to get one entry of yoiur dataset back. E.g. as if you are asking for one sentence about a concept, not however many you want your dataset to contain. The code will handle creating a dataset for you based on the number you added earlier for dataset size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    .widget-label {\n",
       "        white-space: normal;\n",
       "        word-wrap: break-word;\n",
       "        overflow-wrap: break-word;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('''\n",
    "<style>\n",
    "    .widget-label {\n",
    "        white-space: normal;\n",
    "        word-wrap: break-word;\n",
    "        overflow-wrap: break-word;\n",
    "    }\n",
    "</style>\n",
    "'''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Jinja environment\n",
    "template_dir = '../data/inputs/templates'\n",
    "output_dir = '../data/inputs/prompts'\n",
    "env = Environment(loader=FileSystemLoader(template_dir))\n",
    "\n",
    "def load_templates():\n",
    "    \"\"\"Load template files from the template directory.\"\"\"\n",
    "    return [os.path.splitext(f)[0] for f in os.listdir(template_dir) if f.endswith('.j2')]\n",
    "\n",
    "def create_template_dropdown():\n",
    "    \"\"\"Create a dropdown widget for selecting templates.\"\"\"\n",
    "    templates = load_templates()\n",
    "    default_template = 'blank_template'\n",
    "    return Dropdown(options=templates, value=default_template if default_template in templates else None)\n",
    "\n",
    "def create_template_content_input():\n",
    "    \"\"\"Create a textarea widget for editing template content.\"\"\"\n",
    "    return Textarea(rows=10)\n",
    "\n",
    "def create_filename_input():\n",
    "    \"\"\"Create a text input widget for entering a new template filename.\"\"\"\n",
    "    return Text(value='new_template')\n",
    "\n",
    "def create_save_button():\n",
    "    \"\"\"Create a button widget for saving the template.\"\"\"\n",
    "    button = Button(description='Save')\n",
    "    button.on_click(save_template)\n",
    "    return button\n",
    "\n",
    "def create_use_button():\n",
    "    \"\"\"Create a button widget for using the template.\"\"\"\n",
    "    button = Button(description='Use Template')\n",
    "    button.on_click(use_template)\n",
    "    return button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_template(button):\n",
    "    \"\"\"Save the template content to a file.\"\"\"\n",
    "\n",
    "    # Replace any file extension from the text, if existent, with .j2\n",
    "    new_filename = filename_input.value.split('.')[0] + '.j2'\n",
    "    new_template_path = os.path.join(template_dir, new_filename)\n",
    "    if new_filename == \"blank_template.j2\":\n",
    "        with save_warning_output:\n",
    "            print('Cannot overwrite the \"blank_template.j2\" file.')\n",
    "    elif os.path.exists(new_template_path):\n",
    "        with save_warning_output:\n",
    "            print(f'File \"{new_filename}\" already exists. Do you want to overwrite it?')\n",
    "            overwrite_button = Button(description='Overwrite')\n",
    "            overwrite_button.on_click(lambda _: save_template_content(new_template_path, True))\n",
    "            cancel_button = Button(description='Cancel')\n",
    "            cancel_button.on_click(lambda _: save_warning_output.clear_output())\n",
    "            display(overwrite_button, cancel_button)\n",
    "    else:\n",
    "        save_template_content(new_template_path)\n",
    "\n",
    "def save_template_content(file_path, overwrite=False):\n",
    "    \"\"\"Save the template content to the specified file path.\"\"\"\n",
    "\n",
    "    template_content = template_content_input.value\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(template_content)\n",
    "    with success_output:\n",
    "        clear_output()\n",
    "        print(f'Template saved as \"{os.path.basename(file_path)}\".')\n",
    "    \n",
    "    if not overwrite:\n",
    "        # Refresh the template dropdown\n",
    "        template_dropdown.options = load_templates()\n",
    "\n",
    "        new_template_name = os.path.basename(file_path).split('.')[0]\n",
    "        template_dropdown.value = new_template_name\n",
    "\n",
    "def load_template_content(change):\n",
    "    \"\"\"Load the content of the selected template into the template content input.\"\"\"\n",
    "\n",
    "    template_name = change['new'] + '.j2'\n",
    "    template_path = os.path.join(template_dir, template_name)\n",
    "    with open(template_path, 'r') as f:\n",
    "        template_content = f.read()\n",
    "    template_content_input.value = template_content\n",
    "\n",
    "def render_template(template_name, user_input):\n",
    "    \"\"\"Render the template with the provided user input.\"\"\"\n",
    "    template = env.get_template(template_name)\n",
    "    return template.render(**user_input)\n",
    "\n",
    "def use_template(button):\n",
    "    \"\"\"Use the selected template and prompt the user to fill in the\n",
    "    template variables.\"\"\"\n",
    "\n",
    "    template_name = template_dropdown.value + '.j2'\n",
    "    template_source = env.loader.get_source(env, template_name)[0]\n",
    "    parsed_content = env.parse(template_source)\n",
    "    variables = meta.find_undeclared_variables(parsed_content)\n",
    "\n",
    "    load_form = VBox()\n",
    "    placeholders = {}\n",
    "    for var in variables:\n",
    "        placeholder_input = Text(\n",
    "            description=f'Enter value for \"{var}\":',\n",
    "            layout=Layout(width='auto', min_width='200px'),\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        load_form.children += (placeholder_input,)\n",
    "        placeholders[var] = placeholder_input\n",
    "        \n",
    "    output_filename_input = Text(\n",
    "        description='Enter a filename to save the template with these values (e.g. my_prompt):',\n",
    "        layout=Layout(width='auto', min_width='200px'),\n",
    "        style={'description_width': 'initial'})\n",
    "    load_form.children += (output_filename_input,)\n",
    "\n",
    "    render_button = Button(description='Save and Render')\n",
    "    render_warning_output = Output()\n",
    "    \n",
    "    warning_and_buttons_layout = VBox([\n",
    "        render_button,\n",
    "        render_warning_output\n",
    "    ])\n",
    "    \n",
    "    load_form.children += (warning_and_buttons_layout,)\n",
    "\n",
    "    # Apply CSS styling to the form container\n",
    "    load_form.layout.width = '100%'\n",
    "    load_form.layout.min_width = '400px'\n",
    "    load_form.add_class('my-form')\n",
    "    \n",
    "    display(load_form)\n",
    "\n",
    "    def on_render_and_save(button):\n",
    "        \"\"\"Render the template with the provided user input and globally save the rendered text.\"\"\"\n",
    "\n",
    "        rendered_text = render_and_save(button)\n",
    "        if rendered_text is not None:\n",
    "            # Assign the rendered_text to a variable in the global scope using globals()\n",
    "            globals()['rendered_prompt'] = rendered_text\n",
    "    \n",
    "    def render_and_save(button):\n",
    "        \"\"\"Render the template with the provided user input and save the rendered text to a file.\"\"\"\n",
    "\n",
    "        placeholder_values = {var: widget.value for var, widget in placeholders.items()}\n",
    "        rendered_text = render_template(template_name, placeholder_values)\n",
    "        output_filename = output_filename_input.value\n",
    "        \n",
    "        # Remove any existing file extension from the output filename\n",
    "        output_filename = os.path.splitext(output_filename)[0] + '.txt'\n",
    "                \n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            with render_warning_output:\n",
    "                print(f'File \"{output_filename}\" already exists. Do you want to overwrite it?')\n",
    "                overwrite_button = Button(description='Overwrite')\n",
    "                overwrite_button.on_click(lambda _: save_rendered_content(output_path, rendered_text, True))\n",
    "                cancel_button = Button(description='Cancel')\n",
    "                cancel_button.on_click(lambda _: render_warning_output.clear_output())\n",
    "                display(overwrite_button, cancel_button)\n",
    "        else:\n",
    "            save_rendered_content(output_path, rendered_text)\n",
    "        \n",
    "        return rendered_text\n",
    "\n",
    "    render_button.on_click(on_render_and_save)\n",
    "\n",
    "def save_rendered_content(file_path, rendered_text, overwrite=False):\n",
    "    \"\"\"Save the rendered text to the specified file path.\"\"\"\n",
    "\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(rendered_text)\n",
    "    with success_output:\n",
    "        print(f'Rendered text saved as \"{os.path.basename(file_path)}\".')\n",
    "    \n",
    "    # Update the preview output widget with the rendered template\n",
    "    with preview_output:\n",
    "        print('Template Preview:')\n",
    "        print(rendered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_widgets():\n",
    "    \"\"\"Create the widgets used in the form.\"\"\"\n",
    "\n",
    "    global template_dropdown, template_content_input, filename_input, save_button, use_button, preview_button\n",
    "    global save_warning_output, success_output, preview_output\n",
    "\n",
    "    template_dropdown = create_template_dropdown()\n",
    "    template_content_input = create_template_content_input()\n",
    "    filename_input = create_filename_input()\n",
    "    save_button = create_save_button()\n",
    "    use_button = create_use_button()\n",
    "    save_warning_output = Output()\n",
    "    success_output = Output()\n",
    "    preview_output = Output()\n",
    "\n",
    "def create_layout():\n",
    "    \"\"\"Create the main layout of the form.\"\"\"\n",
    "    \n",
    "    input_layout = VBox([\n",
    "        Label(value='Template Manager', style={'font_weight': 'bold', 'font_size': '18px'}),    \n",
    "        Label(value='Create a new template, or select/modify an existing one.'),\n",
    "        template_dropdown,\n",
    "        Label(value='Edit the template content:'),\n",
    "        template_content_input,\n",
    "        Label(value=\"If you have created a new template or modified an existing one, enter a name for it here. Skip this step if you're directly using an existing template without modifying it.\"),\n",
    "        filename_input,\n",
    "    ])\n",
    "    \n",
    "    save_button_layout = HBox([save_button])\n",
    "    \n",
    "    warning_and_success_layout = VBox([\n",
    "        save_warning_output,\n",
    "        success_output\n",
    "    ])\n",
    "    \n",
    "    separator_layout = HBox([Label(value='─' * 50, style={'font_size': '20px'})])\n",
    "    \n",
    "    use_button_description = Label(value='''Once you have decided on a template, let's use it. Once you press the button below, you'll be asked to fill in the relevant variables.''',\n",
    "                                        layout=Layout(width='auto'))\n",
    "    \n",
    "    use_button_layout = HBox([use_button])\n",
    "    \n",
    "    button_layout = VBox([\n",
    "        save_button_layout,\n",
    "        warning_and_success_layout,\n",
    "        separator_layout,\n",
    "        use_button_description,\n",
    "        use_button_layout\n",
    "    ], layout=Layout(margin='20px 0px'))\n",
    "    \n",
    "    output_layout = VBox([\n",
    "        preview_output,\n",
    "    ])\n",
    "    \n",
    "    main_layout = VBox([input_layout, button_layout, output_layout], layout=Layout(width='auto'))\n",
    "    return main_layout\n",
    "\n",
    "def initialize():\n",
    "    create_widgets()\n",
    "    template_dropdown.observe(load_template_content, names='value')\n",
    "    layout = create_layout()\n",
    "    display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85335151256c4b62ab1bad20ad89894b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='Template Manager', style=LabelStyle(font_size='18px', font_weight='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200580f4a77542e08d2a1a911505f6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Enter value for \"context\":', layout=Layout(min_width='200px', width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the code below allows you to check you are happy with your prompt. If not, reload the form and fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendered Prompt:\n",
      "Enter qa and then more c and b\n"
     ]
    }
   ],
   "source": [
    "print(\"Rendered Prompt:\")\n",
    "print(rendered_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below your prompts for generating dataset labels.\n",
    "\n",
    "Instructions\n",
    "\n",
    "- The previous form allows you to generate a dataset of prompts.\n",
    "- The next form allows you to create questions that will label each prompt from the generated set of prompts.\n",
    "- Each generated prompt is sent one by one with the question back through the LLM as a new combined prompt to get the label.\n",
    "- Call a prompt from your generated dataset of prompts P.\n",
    "- Imagine the generated dataset of prompts are either polite or impolite statements e.g.\n",
    "- \"Would you be so kind as to pass the water please.\" or \"Give me the water now.\"\n",
    "- You want to label each prompt as \"polite\" or \"impolite\".\n",
    "- In the following form you will be asked to come up with pairs of \"headings\" and \"labellings\"\n",
    "- A \"heading\" is the name for the column for the labelling in your dataset.\n",
    "- A \"labelling\" is the question you will be asking to label the generated prompt.\n",
    "- In the example below:\n",
    "\n",
    "\n",
    "```\n",
    "prompt, ethical_area, ethical_valence\n",
    "\"Would you be so kind as to pass the water please.\", \"polite\", 1\n",
    "\"Give me the water now.\", \"impolite\", 0\n",
    "```\n",
    "\n",
    "- The headings are \"ethical_area\" and \"ethical_valance\"\n",
    "- The labellings that got us the labels might be:\n",
    "- \"Do you think the start of the response in the following text is polite or impolite? Output only the word \"polite\" for polite, or \"impolite\" for impolite in single word response within single quote marks. Here is the text: \"\n",
    "- \"Do you think the start of the response in the following text is polite or impolite? Output only the number 1 for polite, or 0 for impolite. Here is the text: \"\n",
    "- Call a specific heading H and a specific labelling L.\n",
    "- P and L would be passed back to the LLM as L + P e.g.\n",
    "- \"Do you think the start of the response in the following text is polite or impolite? Output only the word \"polite\" for polite, or \"impolite\" for impolite in single word response within single quote marks. Here is the text: Give me the water now.\"\n",
    "\n",
    "\n",
    "Details\n",
    "\n",
    "- You may need to experiment a little to get good labelling from the LLM.\n",
    "- It is not certain that the LLM will be able to perform the labelling you are asking for, and if it can it may make mistakes.\n",
    "- You need to check the labels are correct both in the Review section and after the full Dataset Generation section.\n",
    "- You need to generate labels for ethical_area and ethical_valency at a minimum for the way the code currently works.\n",
    "- In the example above, ethical_area always map to the same ethical_valency and vice versa. In other words they are synomyms. They need not be though.\n",
    "- Your label's name and the prompt to generate it should be enclosed in quote marks. \n",
    "- It is a good idea to ask the LLM for the single word or number or whatever else you want so it does not add in unnecessary additional comments such as \"Sure, this sentence is impolite\" etc which we do not want as part of our label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeadingLabellingForm(widgets.VBox):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hl_pairs = {}\n",
    "        self.hl_rows = []\n",
    "        \n",
    "        # Directory for saving the dictionary\n",
    "        self.output_dir = '../data/inputs/labels'\n",
    "        \n",
    "        # New explanatory text at the top of the form\n",
    "        self.top_text = widgets.HTML(value=\"\"\"<h3>Heading-Labelling Form</h3>\n",
    "                                     <p>Use this form to load, modify or create heading-labelling schemes.</p>\n",
    "                                     <p>1. To load an existing scheme without modification, select the scheme from the dropdown menu and press the \"Finish button\".</p>\n",
    "                                     <p>2. To modify an existing scheme, select the scheme from the dropdown menu, click the \"Add Heading and Labelling\" button for each new pair you want to add, or modify or delate existing pairs, press the \"Finish\" button, then save.\n",
    "                                     <p>3. To create a new scheme, click the \"Add a pair\" button for each new pair you want to add, or modify or delate as necessary, press the \"Finish\" button, then save.\"\"\")\n",
    "        \n",
    "        # Dropdown for selecting an existing H-L file\n",
    "        self.hl_dropdown = widgets.Dropdown(options=self.load_hl_files(), description='Select a Scheme:')\n",
    "        self.hl_dropdown.observe(self.load_hl_file, names='value')\n",
    "        \n",
    "        # Explanatory text\n",
    "        self.explanatory_text = widgets.HTML(value='<p>Click the \"Add a pair\" button to add a new heading-labelling pair</p>')\n",
    "        \n",
    "        # Add Heading and Labelling button\n",
    "        self.add_button = widgets.Button(description='Add a pair')\n",
    "        self.add_button.on_click(self.add_hl_pair)\n",
    "        self.add_button.layout.width = '200px'\n",
    "        \n",
    "        # Finish Headings button\n",
    "        self.finish_button = widgets.Button(description='Finish')\n",
    "        self.finish_button.on_click(self.finish_headings)\n",
    "        self.finish_button.layout.width = '200px'\n",
    "        \n",
    "        self.output = widgets.Output()\n",
    "        \n",
    "        # Filename input\n",
    "        self.filename_input = widgets.Text(placeholder='Enter a name for this scheme')\n",
    "        self.filename_input.layout.width = '300px'\n",
    "        \n",
    "        # Save Dictionary button\n",
    "        self.save_button = widgets.Button(description='Save')\n",
    "        self.save_button.on_click(self.save_dictionary)\n",
    "        self.save_button.layout.width = '200px'\n",
    "        \n",
    "        self.warning_output = widgets.Output()\n",
    "        \n",
    "        # Add widgets to the layout\n",
    "        self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]\n",
    "\n",
    "    def load_hl_files(self):\n",
    "        return [os.path.splitext(f)[0] for f in os.listdir(self.output_dir) if f.endswith('.json')]\n",
    "\n",
    "    def load_hl_file(self, change):\n",
    "        hl_filename = change['new'] + '.json'\n",
    "        hl_file_path = os.path.join(self.output_dir, hl_filename)\n",
    "        with open(hl_file_path, 'r') as file:\n",
    "            self.hl_pairs = json.load(file)\n",
    "        \n",
    "        self.hl_rows = []\n",
    "        for heading, labelling in self.hl_pairs.items():\n",
    "            heading_input = widgets.Text(value=heading)\n",
    "            labelling_input = widgets.Text(value=labelling)\n",
    "            labelling_input.layout.width = '100%'\n",
    "            remove_button = widgets.Button(description='Remove')\n",
    "            remove_button.layout.width = '80px'\n",
    "            remove_button.on_click(self.remove_hl_pair)\n",
    "            row = widgets.HBox([heading_input, labelling_input, remove_button])\n",
    "            self.hl_rows.append(row)\n",
    "        \n",
    "        self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, *self.hl_rows, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]\n",
    "\n",
    "    def update_hl_rows(self):\n",
    "        self.hl_rows = []\n",
    "        new_hl_pairs = {}\n",
    "        for heading, labelling in self.hl_pairs.items():\n",
    "            heading_input = widgets.Text(value=heading)\n",
    "            labelling_input = widgets.Text(value=labelling)\n",
    "            labelling_input.layout.width = '100%'\n",
    "            remove_button = widgets.Button(description='Remove')\n",
    "            remove_button.layout.width = '80px'\n",
    "            remove_button.on_click(self.remove_hl_pair)\n",
    "            row = widgets.HBox([heading_input, labelling_input, remove_button])\n",
    "            self.hl_rows.append(row)\n",
    "            new_hl_pairs[heading_input] = labelling_input\n",
    "        self.hl_pairs = new_hl_pairs\n",
    "        self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, *self.hl_rows, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]\n",
    "\n",
    "    def add_hl_pair(self, button):\n",
    "        heading_input = widgets.Text(placeholder='Enter heading key')\n",
    "        labelling_input = widgets.Text(placeholder='Enter labelling')\n",
    "        labelling_input.layout.width = '100%'\n",
    "        remove_button = widgets.Button(description='Remove')\n",
    "        remove_button.layout.width = '80px'\n",
    "        remove_button.on_click(self.remove_hl_pair)\n",
    "        row = widgets.HBox([heading_input, labelling_input, remove_button])\n",
    "        self.hl_rows.append(row)\n",
    "        self.hl_pairs[heading_input] = labelling_input\n",
    "        self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, *self.hl_rows, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]\n",
    "\n",
    "    def finish_headings(self, button):\n",
    "        self.hl_pairs = {heading.value.strip(): labelling.value.strip() for heading, labelling in zip([row.children[0] for row in self.hl_rows], [row.children[1] for row in self.hl_rows]) if heading.value.strip() and labelling.value.strip()}\n",
    "        self.output.clear_output()\n",
    "        with self.output:\n",
    "            display(widgets.HTML(f'<p>Heading-Labelling pairs:</p><pre>{self.hl_pairs}</pre>'))\n",
    "        globals()['hl_pairs'] = self.hl_pairs\n",
    "\n",
    "    def save_dictionary(self, button):\n",
    "        filename = self.filename_input.value.strip()\n",
    "        if not filename:\n",
    "            self.warning_output.clear_output()\n",
    "            with self.warning_output:\n",
    "                print(\"Please enter a filename.\")\n",
    "            return\n",
    "        \n",
    "        if not filename.endswith('.json'):\n",
    "            filename += '.json'\n",
    "        \n",
    "        file_path = os.path.join(self.output_dir, filename)\n",
    "        \n",
    "        if os.path.exists(file_path):\n",
    "            self.warning_output.clear_output()\n",
    "            with self.warning_output:\n",
    "                print(f'File \"{filename}\" already exists. Do you want to overwrite it?')\n",
    "                overwrite_button = widgets.Button(description='Overwrite')\n",
    "                overwrite_button.on_click(lambda _: self.save_dictionary_to_file(file_path))\n",
    "                cancel_button = widgets.Button(description='Cancel')\n",
    "                cancel_button.on_click(lambda _: self.warning_output.clear_output())\n",
    "                display(widgets.HBox([overwrite_button, cancel_button]))\n",
    "        else:\n",
    "            self.save_dictionary_to_file(file_path)\n",
    "            \n",
    "            # Refresh the dropdown options and select the newly saved file\n",
    "            self.hl_dropdown.options = self.load_hl_files()\n",
    "            self.hl_dropdown.value = os.path.splitext(filename)[0]\n",
    "\n",
    "    def save_dictionary_to_file(self, file_path):\n",
    "        with open(file_path, 'w') as file:\n",
    "            json.dump(self.hl_pairs, file)\n",
    "        \n",
    "        self.warning_output.clear_output()\n",
    "        with self.output:\n",
    "            print(f'Dictionary saved as \"{file_path}\".')\n",
    "\n",
    "    def remove_hl_pair(self, button):\n",
    "        row = None\n",
    "        for r in self.hl_rows:\n",
    "            if button in r.children:\n",
    "                row = r\n",
    "                break\n",
    "        if row:\n",
    "            self.hl_rows.remove(row)\n",
    "            heading_input = row.children[0]\n",
    "            del self.hl_pairs[heading_input]\n",
    "            row.close()\n",
    "            self.children = [self.top_text, self.hl_dropdown, self.explanatory_text, self.add_button, *self.hl_rows, self.finish_button, self.output, self.filename_input, self.save_button, self.warning_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13a90f9c64944d448adc605907929ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HeadingLabellingForm(children=(HTML(value='<h3>Heading-Labelling Form</h3>\\n                                  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qa_form = HeadingLabellingForm()\n",
    "display(qa_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H-L Pairs:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'hl_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH-L Pairs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mhl_pairs\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hl_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"H-L Pairs:\")\n",
    "print(hl_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "You do not need to alter the code in any of the cells from here or on. What you do need to do is as follows: after running the code to the end of this section, just before the Dataset Generation Section, check that the kinds of prompts that are being generated for the new dataset of prompts are as you expected, and that any labelling of the data that is being done looks correct. This is to save you wasting time and money by avoiding generating the whole dataset but then not liking the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! CHECK YOUR DATASET SAMPLE HERE BEFORE CONTINUING!!!\n",
    "\n",
    "If you are happy with the results, continue, if not, go back to the start of the Inputs section and work through to this point again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: ../data/inputs/datasets/justice\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = os.path.join(\"../data/inputs/datasets\", filestem)\n",
    " \n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "    print(f\"Directory created: {dataset_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset by calling the OpenAI API\n",
    "def generate_dataset_from_prompt(prompt,\n",
    "                                 generated_dataset_file_path,\n",
    "                                 model,\n",
    "                                 log_file_path,\n",
    "                                 i):\n",
    "    completion = client.chat.completions.create(\n",
    "            **{\n",
    "                \"model\": model,\n",
    "                \"temperature\": temperature,\n",
    "                \"seed\": i,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    completion_words = completion.choices[0].message.content.strip()\n",
    "\n",
    "    # cleaned_completion = completion.choices[0].message.content.strip()[3:-3]\n",
    "    print(\" \")\n",
    "    print(completion_words)\n",
    "    print(\" \")\n",
    "\n",
    "    # Open a file in write mode ('w') and save the CSV data\n",
    "    with open(generated_dataset_file_path+\"_\"+str(i)+\".txt\", 'w', newline='', encoding='utf-8') as file:\n",
    "        file.write(completion_words)\n",
    "\n",
    "    num_words_in_prompt = count_words_in_string(prompt)\n",
    "    num_words_in_completion = count_words_in_string(completion_words)\n",
    "    total_words = num_words_in_prompt + num_words_in_completion\n",
    "\n",
    "    num_tokens_in_prompt = completion.usage.prompt_tokens\n",
    "    num_tokens_in_completion = completion.usage.completion_tokens\n",
    "    total_tokens = num_tokens_in_prompt + num_tokens_in_completion\n",
    "\n",
    "    prompt_cost = num_tokens_in_prompt*0.01/1000\n",
    "    completion_cost = num_tokens_in_completion*0.03/1000\n",
    "    total_cost = prompt_cost + completion_cost\n",
    "    \n",
    "    tokens_per_prompt_word = num_words_in_prompt/num_tokens_in_prompt\n",
    "    tokens_per_completion_word = num_words_in_completion/num_tokens_in_completion\n",
    "\n",
    "    log = {\n",
    "            \"num_words_in_prompt\": num_words_in_prompt,\n",
    "            \"num_words_in_completion\": num_words_in_completion,\n",
    "            \"total_words\": total_words,\n",
    "            \"num_tokens_in_prompt\": num_tokens_in_prompt,\n",
    "            \"num_tokens_in_completion\": num_tokens_in_completion,\n",
    "            \"total_tokens\": total_tokens,\n",
    "            \"prompt_cost\": prompt_cost,\n",
    "            \"completion_cost\": completion_cost,\n",
    "            \"total_cost\": total_cost,\n",
    "            \"tokens_per_prompt_word\": tokens_per_prompt_word,\n",
    "            \"tokens_per_completion_word\": tokens_per_completion_word\n",
    "\n",
    "    }\n",
    "\n",
    "    for k, v in log.items():\n",
    "        print(k, v)\n",
    "    print(\" \")\n",
    "\n",
    "    with open(log_file_path+\"_\"+str(i)+\".txt\", 'w') as file:\n",
    "        file.write(json.dumps(log, indent=4))\n",
    "\n",
    "def count_words_in_string(input_string):\n",
    "    words = input_string.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Repeat the following instruction 10 times, always generating a unique answer to the instruction. Begin instruction: Enter qa and then more c and b End instruction. Put the result of each instruction within a pair quote marks on a new line as if each was the row of a single column csv and include no other text.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = f\"Repeat the following instruction 10 times, always generating a unique answer to the instruction. Begin instruction: {rendered_prompt} End instruction. Put the result of each instruction within a pair quote marks on a new line as if each was the row of a single column csv and include no other text.\"\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Generate sample dataset\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[43mgenerate_dataset_from_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerated_dataset_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     23\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m end_time \u001b[38;5;241m-\u001b[39m start_time\n",
      "Cell \u001b[0;32mIn[21], line 7\u001b[0m, in \u001b[0;36mgenerate_dataset_from_prompt\u001b[0;34m(prompt, generated_dataset_file_path, model, log_file_path, i)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_dataset_from_prompt\u001b[39m(prompt,\n\u001b[1;32m      3\u001b[0m                                  generated_dataset_file_path,\n\u001b[1;32m      4\u001b[0m                                  model,\n\u001b[1;32m      5\u001b[0m                                  log_file_path,\n\u001b[1;32m      6\u001b[0m                                  i):\n\u001b[0;32m----> 7\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      8\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m      9\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m     10\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m     11\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: i,\n\u001b[1;32m     12\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\n\u001b[1;32m     13\u001b[0m                     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a helpful assistant.\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m     14\u001b[0m                     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[1;32m     15\u001b[0m                 ]\n\u001b[1;32m     16\u001b[0m             }\n\u001b[1;32m     17\u001b[0m         )\n\u001b[1;32m     19\u001b[0m     completion_words \u001b[38;5;241m=\u001b[39m completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# cleaned_completion = completion.choices[0].message.content.strip()[3:-3]\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate the sample dataset\n",
    "\n",
    "# First save the prompt as a text file\n",
    "with open(dataset_dir+\"/prompt.txt\", 'w', newline='', encoding='utf-8') as file:\n",
    "    file.write(prompt)\n",
    "\n",
    "# Define the file path for the generated dataset\n",
    "generated_dataset_file_path = os.path.join(dataset_dir, f\"{filestem}\")\n",
    "\n",
    "# Define the log file path\n",
    "log_file_path = os.path.join(dataset_dir, \"log\")\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = math.ceil(total_num_examples/num_examples_per_request)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate sample dataset\n",
    "generate_dataset_from_prompt(prompt, generated_dataset_file_path, model, log_file_path, 0)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The code took {elapsed_time} seconds to run.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/inputs/datasets/justice'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/inputs/datasets/justice/justice'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_dataset_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      " \n",
      "\"In a courtroom, where truth should guide the scales, often bias tips the balance, revealing the stark opposite of justice.\"\n",
      "\"Every wrongful conviction is a stark reminder of justice denied, echoing the flaws within the beams of the American justice system.\"\n",
      "\"In the heart of the justice system, where equality should stand paramount, oftentimes it's the disparity that takes the stage, showcasing the antithesis of justice.\"\n",
      "\"For many, the American dream is tarnished by a justice system that too frequently fails to uphold its promise of fair treatment for all.\"\n",
      "\"The ideal of blind justice is frequently unmet, as socioeconomic status and ethnicity continue to influence outcomes in the criminal justice system.\"\n",
      "\"A moment of true justice shines when a wrongfully convicted individual steps back into the light of freedom, correcting a grievous error.\"\n",
      "\"Justice is served when the innocent are protected and the guilty are held accountable, a principle that remains the cornerstone of the U.S. criminal justice system.\"\n",
      "\"When a person is judged by the content of their character and not the depth of their pockets, then justice in its truest form is served.\"\n",
      "\"Every exoneration is a bittersweet victory, highlighting both the potential for rectitude and the prevalent injustice within the American criminal justice system.\"\n",
      "\"Amidst a sea of injustices, when the system upholds fairness and impartiality, it rekindles the beacon of hope for what justice can truly signify.\"\n",
      " \n",
      "num_words_in_prompt 88\n",
      "num_words_in_completion 232\n",
      "total_words 320\n",
      "num_tokens_in_prompt 117\n",
      "num_tokens_in_completion 283\n",
      "total_tokens 400\n",
      "prompt_cost 0.00117\n",
      "completion_cost 0.008490000000000001\n",
      "total_cost 0.009660000000000002\n",
      "tokens_per_prompt_word 0.7521367521367521\n",
      "tokens_per_completion_word 0.8197879858657244\n",
      " \n",
      "The code took 14.584094762802124 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "# Define the number of iterations\n",
    "num_iterations = math.ceil(total_num_examples/num_examples_per_request)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate the dataset\n",
    "for i in range(num_iterations):\n",
    "    print(\"Iteration: \", i)\n",
    "    generate_dataset_from_prompt(prompt, generated_dataset_file_path, model, log_file_path, i+1)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The code took {elapsed_time} seconds to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['justice_1.txt']\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all the files you want to process\n",
    "# Makes sure they all have the same prompt context\n",
    "# eg won;t mix up honest with justice etc\n",
    "files = [f for f in os.listdir(dataset_dir) \n",
    "                      if f.endswith('.txt') and filestem in f.lower()]\n",
    "\n",
    "print(files)\n",
    "\n",
    "# Define the regular expression pattern\n",
    "# Get lines that start with a quote,\n",
    "# then have any number of characters,\n",
    "# then end with a quote and possibly comma\n",
    "# We're trying to find all valid CSV lines\n",
    "pattern = r'^\\\".*\\\",?[\\r\\n]*'\n",
    "\n",
    "# Open the master CSV file\n",
    "with open(os.path.join(dataset_dir, filestem+\"_unlabelled.csv\"), \"a\") as master:\n",
    "    # Loop over the files\n",
    "    for file in files:\n",
    "        # Open the current file and read its contents\n",
    "        with open(os.path.join(dataset_dir, file), 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Use the re.findall function to find all matches in the content\n",
    "        matches = re.findall(pattern, content, re.MULTILINE)        \n",
    "\n",
    "        # Loop over the matches\n",
    "        for match in matches:\n",
    "            \n",
    "            # Remove any trailing commas and newline characters\n",
    "            match_cleaned = match.rstrip(',\\r\\n')\n",
    "            \n",
    "            # Append the match to the master CSV file\n",
    "            master.write(match_cleaned + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add optional columns for classification\n",
    "\n",
    "The columns added here work with the defaults currently hardcoded into the data analysis\n",
    "This hardcoding will be resolved soon for more flexibility.\n",
    "\n",
    "I show examples of using am LLM to auto-label and a way to label if you knw in advance which rows are of which kind of label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of labelling using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\"ethical_area\"': '\"Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" including quote marks for just, or \"unjust\" including quote marks for unjust in a single word response. Here is the text: \"',\n",
       " '\"ethical_valence\"': '\"Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: \"'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hl_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Row 1: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: In a courtroom, where truth should guide the scales, often bias tips the balance, revealing the stark opposite of justice.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: In a courtroom, where truth should guide the scales, often bias tips the balance, revealing the stark opposite of justice.\n",
      "\n",
      "Row 2: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: Every wrongful conviction is a stark reminder of justice denied, echoing the flaws within the beams of the American justice system.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: Every wrongful conviction is a stark reminder of justice denied, echoing the flaws within the beams of the American justice system.\n",
      "\n",
      "Row 3: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: In the heart of the justice system, where equality should stand paramount, oftentimes it's the disparity that takes the stage, showcasing the antithesis of justice.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: In the heart of the justice system, where equality should stand paramount, oftentimes it's the disparity that takes the stage, showcasing the antithesis of justice.\n",
      "\n",
      "Row 4: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: For many, the American dream is tarnished by a justice system that too frequently fails to uphold its promise of fair treatment for all.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: For many, the American dream is tarnished by a justice system that too frequently fails to uphold its promise of fair treatment for all.\n",
      "\n",
      "Row 5: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: The ideal of blind justice is frequently unmet, as socioeconomic status and ethnicity continue to influence outcomes in the criminal justice system.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: The ideal of blind justice is frequently unmet, as socioeconomic status and ethnicity continue to influence outcomes in the criminal justice system.\n",
      "\n",
      "Row 6: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: A moment of true justice shines when a wrongfully convicted individual steps back into the light of freedom, correcting a grievous error.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: A moment of true justice shines when a wrongfully convicted individual steps back into the light of freedom, correcting a grievous error.\n",
      "\n",
      "Row 7: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: Justice is served when the innocent are protected and the guilty are held accountable, a principle that remains the cornerstone of the U.S. criminal justice system.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: Justice is served when the innocent are protected and the guilty are held accountable, a principle that remains the cornerstone of the U.S. criminal justice system.\n",
      "\n",
      "Row 8: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: When a person is judged by the content of their character and not the depth of their pockets, then justice in its truest form is served.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: When a person is judged by the content of their character and not the depth of their pockets, then justice in its truest form is served.\n",
      "\n",
      "Row 9: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: Every exoneration is a bittersweet victory, highlighting both the potential for rectitude and the prevalent injustice within the American criminal justice system.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: Every exoneration is a bittersweet victory, highlighting both the potential for rectitude and the prevalent injustice within the American criminal justice system.\n",
      "\n",
      "Row 10: \n",
      "Do you think the start of the response in the following text is just or unjust? Output only the word \"just\" for just, or \"unjust\" for unjust in a single word response. Here is the text: Amidst a sea of injustices, when the system upholds fairness and impartiality, it rekindles the beacon of hope for what justice can truly signify.\n",
      "Do you think the start of the response in the following text is just or unjust? Output only the number 1 for just, or 0 for unjust. Here is the text: Amidst a sea of injustices, when the system upholds fairness and impartiality, it rekindles the beacon of hope for what justice can truly signify.\n"
     ]
    }
   ],
   "source": [
    "def ask_openai(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "                **{\n",
    "                    \"model\": model,\n",
    "                    \"temperature\": 0, # For most deterministic results\n",
    "                    \"seed\": 0, # For reproducibility\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "input_file_path = generated_dataset_file_path+\"_unlabelled.csv\"\n",
    "output_file_path = generated_dataset_file_path+\"_labelled.csv\"\n",
    "\n",
    "\n",
    "with open(input_file_path, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    \n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    header = [\"prompt\"]\n",
    "\n",
    "    # Add a header\n",
    "    for column_name in hl_pairs.keys():\n",
    "        header.append(column_name)\n",
    "    \n",
    "    writer.writerow(header)\n",
    "    \n",
    "    for i, row in enumerate(reader):\n",
    "        print(f\"\\nRow {i+1}: \")\n",
    "        for labelling in hl_pairs.values():\n",
    "            # Assuming each row contains a single column with your text\n",
    "            statement = row[0]  # Adjust this if your structure is different\n",
    "            # Here you define the question you want to ask about each row\n",
    "            labelling_prompt = f\"{labelling} {statement}\"\n",
    "            print(labelling_prompt)\n",
    "            response = ask_openai(labelling_prompt)\n",
    "            # Add the OpenAI response to the row\n",
    "            row.append(response)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect dataset random sample (set to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>ethical_area</th>\n",
       "      <th>ethical_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ideal of blind justice is frequently unmet, as socioeconomic status and ethnicity continue to influence outcomes in the criminal justice system.</td>\n",
       "      <td>unjust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Every exoneration is a bittersweet victory, highlighting both the potential for rectitude and the prevalent injustice within the American criminal justice system.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Justice is served when the innocent are protected and the guilty are held accountable, a principle that remains the cornerstone of the U.S. criminal justice system.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A moment of true justice shines when a wrongfully convicted individual steps back into the light of freedom, correcting a grievous error.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For many, the American dream is tarnished by a justice system that too frequently fails to uphold its promise of fair treatment for all.</td>\n",
       "      <td>unjust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Every wrongful conviction is a stark reminder of justice denied, echoing the flaws within the beams of the American justice system.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amidst a sea of injustices, when the system upholds fairness and impartiality, it rekindles the beacon of hope for what justice can truly signify.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When a person is judged by the content of their character and not the depth of their pockets, then justice in its truest form is served.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a courtroom, where truth should guide the scales, often bias tips the balance, revealing the stark opposite of justice.</td>\n",
       "      <td>unjust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the heart of the justice system, where equality should stand paramount, oftentimes it's the disparity that takes the stage, showcasing the antithesis of justice.</td>\n",
       "      <td>unjust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                 prompt  \\\n",
       "4                  The ideal of blind justice is frequently unmet, as socioeconomic status and ethnicity continue to influence outcomes in the criminal justice system.   \n",
       "8    Every exoneration is a bittersweet victory, highlighting both the potential for rectitude and the prevalent injustice within the American criminal justice system.   \n",
       "6  Justice is served when the innocent are protected and the guilty are held accountable, a principle that remains the cornerstone of the U.S. criminal justice system.   \n",
       "5                             A moment of true justice shines when a wrongfully convicted individual steps back into the light of freedom, correcting a grievous error.   \n",
       "3                              For many, the American dream is tarnished by a justice system that too frequently fails to uphold its promise of fair treatment for all.   \n",
       "1                                   Every wrongful conviction is a stark reminder of justice denied, echoing the flaws within the beams of the American justice system.   \n",
       "9                    Amidst a sea of injustices, when the system upholds fairness and impartiality, it rekindles the beacon of hope for what justice can truly signify.   \n",
       "7                              When a person is judged by the content of their character and not the depth of their pockets, then justice in its truest form is served.   \n",
       "0                                            In a courtroom, where truth should guide the scales, often bias tips the balance, revealing the stark opposite of justice.   \n",
       "2  In the heart of the justice system, where equality should stand paramount, oftentimes it's the disparity that takes the stage, showcasing the antithesis of justice.   \n",
       "\n",
       "  ethical_area  ethical_valence  \n",
       "4       unjust                0  \n",
       "8         just                1  \n",
       "6         just                1  \n",
       "5         just                1  \n",
       "3       unjust                0  \n",
       "1         just                1  \n",
       "9         just                1  \n",
       "7         just                1  \n",
       "0       unjust                0  \n",
       "2       unjust                0  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "df = pd.read_csv(generated_dataset_file_path+\"_labelled.csv\")\n",
    "\n",
    "num_samples = 10\n",
    "sample_df = df.sample(num_samples)\n",
    "\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>ethical_area</th>\n",
       "      <th>ethical_valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In a courtroom, where truth should guide the scales, often bias tips the balance, revealing the stark opposite of justice.</td>\n",
       "      <td>unjust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Every wrongful conviction is a stark reminder of justice denied, echoing the flaws within the beams of the American justice system.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the heart of the justice system, where equality should stand paramount, oftentimes it's the disparity that takes the stage, showcasing the antithesis of justice.</td>\n",
       "      <td>unjust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>For many, the American dream is tarnished by a justice system that too frequently fails to uphold its promise of fair treatment for all.</td>\n",
       "      <td>unjust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The ideal of blind justice is frequently unmet, as socioeconomic status and ethnicity continue to influence outcomes in the criminal justice system.</td>\n",
       "      <td>unjust</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A moment of true justice shines when a wrongfully convicted individual steps back into the light of freedom, correcting a grievous error.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Justice is served when the innocent are protected and the guilty are held accountable, a principle that remains the cornerstone of the U.S. criminal justice system.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>When a person is judged by the content of their character and not the depth of their pockets, then justice in its truest form is served.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Every exoneration is a bittersweet victory, highlighting both the potential for rectitude and the prevalent injustice within the American criminal justice system.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Amidst a sea of injustices, when the system upholds fairness and impartiality, it rekindles the beacon of hope for what justice can truly signify.</td>\n",
       "      <td>just</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                 prompt  \\\n",
       "0                                            In a courtroom, where truth should guide the scales, often bias tips the balance, revealing the stark opposite of justice.   \n",
       "1                                   Every wrongful conviction is a stark reminder of justice denied, echoing the flaws within the beams of the American justice system.   \n",
       "2  In the heart of the justice system, where equality should stand paramount, oftentimes it's the disparity that takes the stage, showcasing the antithesis of justice.   \n",
       "3                              For many, the American dream is tarnished by a justice system that too frequently fails to uphold its promise of fair treatment for all.   \n",
       "4                  The ideal of blind justice is frequently unmet, as socioeconomic status and ethnicity continue to influence outcomes in the criminal justice system.   \n",
       "5                             A moment of true justice shines when a wrongfully convicted individual steps back into the light of freedom, correcting a grievous error.   \n",
       "6  Justice is served when the innocent are protected and the guilty are held accountable, a principle that remains the cornerstone of the U.S. criminal justice system.   \n",
       "7                              When a person is judged by the content of their character and not the depth of their pockets, then justice in its truest form is served.   \n",
       "8    Every exoneration is a bittersweet victory, highlighting both the potential for rectitude and the prevalent injustice within the American criminal justice system.   \n",
       "9                    Amidst a sea of injustices, when the system upholds fairness and impartiality, it rekindles the beacon of hope for what justice can truly signify.   \n",
       "\n",
       "  ethical_area  ethical_valence  \n",
       "0       unjust                0  \n",
       "1         just                1  \n",
       "2       unjust                0  \n",
       "3       unjust                0  \n",
       "4       unjust                0  \n",
       "5         just                1  \n",
       "6         just                1  \n",
       "7         just                1  \n",
       "8         just                1  \n",
       "9         just                1  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
