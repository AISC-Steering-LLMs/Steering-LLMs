{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to use a prompt given to some LLM (\"LLM A\") to generate a dataset of different prompts to be fed to some other LLM (\"LLM B\" - potentially the same as \"LLM A\") for which you have access to the weights. This dataset of prompts will be used to create a \"representation vector\" of a property or concept for LLM B in order to \"steer\" LLM B to have more of that property or concept in its outputs. This Notebook does not cover the creation of representations or steering, only the the creation of a dataset of prompts.\n",
    "\n",
    "The kinds of prompts you want to generate should be about the property or concept you want to steer the LLM towards, not necessary literally mentioning it - e.g. prompts about politeness do not necessarily need to have the word polite in them. Part of the point of dataset creation is to explore which kinds of generated prompts yield good representations.\n",
    "\n",
    "The Notebook works as follows:\n",
    "\n",
    "- The Setup section loads Python libraries needed to run the code. You do not need to change anything here.\n",
    "- The Inputs section is where you define the prompt you will use to generate your dataset of prompts. Instructions on how to do this are given. This is the only section of the notebook where you will need to change anything.\n",
    "- The Review section then generates a small example dataset of prompts and shows them to you. If you like them, continue on to the end of the Notebook.\n",
    "- If you do not like them, please go back to the Inputs section to refine your prompt to generate your dataset of prompts.\n",
    "- The Dataset Generation section completes the dataset generation\n",
    "- The View Dataset section loads your generated dataset for inspection.\n",
    "- Your dataset will be stored in /data/inputs/name_of_your_dataset/dataset if you want to use it later.\n",
    "\n",
    "The datasets will be generated in CSV format and should have the following form, where the first line is the column headings, the the next two lines are example prompts. The columns ethical_area and ethical_valence are two different labels (classifications) of the prompt. The Notebook will help you generate these labels. This example is for \"politeness\" prompts:\n",
    "\n",
    "```\n",
    "prompt, ethical_area, ethical_valence\n",
    "\"Would you be so kind as to pass the water please.\", \"polite\", 1\n",
    "\"Give me the water now.\", \"impolite\", 0\n",
    "```\n",
    "\n",
    "If this is too restrictive, you will be able to create other columns and the notebook will ask you about that too.\n",
    "\n",
    "Note that where we have text, such as for the prompt or ethical_area, we want it enclosed in quote marks. Lone numbers do not need this.\n",
    "\n",
    "If there is something unusual you want to do that the current notebook does not permist, please ask, or feel free to try adding code for it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup (just run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayushkucheria/Documents/Steering-LLMs/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/aayushkucheria/Documents/Steering-LLMs/venv/lib/python3.10/site-packages/torch/cuda/__init__.py:740: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11070). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() if nvml_count < 0 else nvml_count\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import main\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "import yaml\n",
    "from hydra import initialize\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from hydra.experimental import compose\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# For refactored code\n",
    "# Need to tidy this up and remove duplicates\n",
    "\n",
    "from data_handler import DataHandler\n",
    "from data_analyser import DataAnalyzer\n",
    "from model_handler import ModelHandler\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "\n",
    "# For datsaet generation\n",
    "import IPython\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "import yaml\n",
    "from ipywidgets import widgets, VBox, Button, Checkbox, Text, IntText, FloatText, SelectMultiple, Label\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing template or create new one (menu/picker)\n",
    "# Be able to load existing template - see the result on a form - be able to modify and save it\n",
    "# Be able to create dictionary from form of placeholders and their content\n",
    "# Need to be able to select number of new placeholders if creating from scratch or modifying\n",
    "\n",
    "\n",
    "# Templates for labelling (menu/picker)\n",
    "\n",
    "# Templates folder, labelling folder\n",
    "\n",
    "# random seed but record seeds\n",
    "# length\n",
    "# Sample from top 5?\n",
    "\n",
    "# higher shot in k-shot\n",
    "# bigger model - more expensive\n",
    "\n",
    "# What is the current context window?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything you might need to alter to change your prompt dataset generation requirements is in this inputs section of the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!CAUTION!!! Enter below your OpenAI API key within the quote marks \" \".\n",
    "\n",
    "- This is not safe practice but will allow the Notebook to run.\n",
    "- Better practice is to store the key in your environment variables. Please ask if you would like help with this.\n",
    "- If you plan to push or share this code in any other way, make sure to remove your API key from this section.\n",
    "\n",
    "```\n",
    "client = OpenAI(\n",
    "    api_key=\"your_api_key_goes_here\"\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = OpenAI(\n",
    "#    api_key=\"fake_key\"\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the next cell represents the better practice for using your API key if it is saved in your environment variables.\n",
    "\n",
    "- This code is currenty \"commented out\" (has the # symbol in front of each line). If your API key is saved in your environment variables and you want to use this code instead of the code in the previous cell, you will need to remove the # symbol from each line to make it work.\n",
    "- There will be nothing to add to this code beyond removing the # symbols.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOPENAI_API_KEY\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Steering-LLMs/venv/lib/python3.10/site-packages/openai/_client.py:98\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[0;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[1;32m     96\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "client = OpenAI(\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the name of the OpenAI model to use within the quote marks.\n",
    "\n",
    "- Select the model from the list of allowable models in the OpenAI API given your subscription level (create an account and get an API ket here: https://auth0.openai.com/u/signup/identifier?state=hKFo2SA1REJ3dGFZVTllNHFvYUFkY2RrWEJpUUVMUWxvel91VqFur3VuaXZlcnNhbC1sb2dpbqN0aWTZIFg1Z2NKOU9hUk4yYUFmWGxyTHlscmtNTmMxbDF5dWZTo2NpZNkgRFJpdnNubTJNdTQyVDNLT3BxZHR3QjNOWXZpSFl6d0Q).\n",
    "- You will need to put some token amount of money on to use gpt-4-0125-preview. It's something like $1. Might be $10.\n",
    "- This is unlikely to change unless the list of available models is updated. See here for the list of models: https://platform.openai.com/docs/models/gpt-4-and-gpt-4-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4-0125-preview\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the model temperature. \n",
    "\n",
    "- From the OpenAI API documentation (https://platform.openai.com/docs/guides/text-generation/how-should-i-set-the-temperature-parameter): \"Lower values for temperature result in more consistent outputs (e.g. 0.2), while higher values generate more diverse and creative results (e.g. 1.0). Select a temperature value based on the desired trade-off between coherence and creativity for your specific application. The temperature can range is from 0 to 2.\"\n",
    "- If your generated sentences are too similar/boring, try increasing the number. Go the other way if too wacky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the filename (the vaiable is called filestem) without the file extension (e.g. .csv) to save the dataset to.\n",
    "\n",
    "- Don't worry about the file ending. It will be a csv. If you call your filename \"honesty\", then your dataset will be in honesty.csv\n",
    "- Try to give it a specific name e.g. \"honesty_v2.csv\" or \"honesty_pairs_v2.csv\", something that will help you remember what it is especially if you are experimenting with variations.\n",
    "- Giving it the same name as an existing dataset will currently overwrite the existing dataset. It should always end in \".csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filestem = \"honesty\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the total number of prompts you want to generate in your dataset of prompts.\n",
    "\n",
    "- We are about to use a prompt to generate a datset of prompt examples.\n",
    "- If you want to generate 10 prompts in total, put 10 here.\n",
    "- If you want to generate 1000 prompts in total, put 1000 here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_examples = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below the number of examples per request. This is the number of prompt examples you want to generate in one request to the LLM.\n",
    "\n",
    "- This is different from the total_num_examples variable you entered above.\n",
    "- The reason we have this is because the LLM has a limit on the number of tokens it can process in one request. If you put a number that is too high here, you will not get the number of prompts you want.\n",
    "- The number of tokens for gpt-4-0125-preview is 4096.\n",
    "- From a quick internet search, I think this model uses about 1.3 tokens per word. So you might have about 4096/1.3 = 3150 words to play with if using this model. Remember, the number of tokens or words includes those in the prompt.\n",
    "- Depending on the size of your prompt and the size of each example you plan to generate, you may need to adjust this number.\n",
    "- This Notebook will make sure that the total number of examples you want to generate as defined in total_num_examples are generated, but it will make multiple requests to the LLM. Eg if you made total_num_examples = 100 and num_examples_per_request = 5, then this code will automatically make 100/5 = 20 requests to the LLM to generate the 100 examples you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_per_request = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for Aayush:\n",
    "\n",
    "- The code below basically works. It's a first pass I did super fast with the new Claude 3 model (really good).\n",
    "- I didn't try to understand it all or optimize it, I just wanted it to basically do what I wanted. sYou can see form looking at it is it not perfect and doesnlt completely make sense, but we can improve it.\n",
    "\n",
    "## End of note for Aayush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to modify an existing templete or create a new one, please run the cell below, otherwise skip to the next cell to load an existing template without modifying it.\n",
    "\n",
    "To modify an existing template:\n",
    "- You will be asked to load a select a template.\n",
    "- Clicking on the template will load it into the Modify Template box below.\n",
    "- Create a new filename and click save.\n",
    "- You cannot overwirte existing templates. Modifications have to be saved with new names.\n",
    "\n",
    "To create a new template (this could be better):\n",
    "- Load any existing template\n",
    "- Delete its contents\n",
    "- Write what you want\n",
    "- Create a new filename and click save.\n",
    "- You cannot overwirte existing templates. New templates have to be saved with new names.\n",
    "\n",
    "What is a template?\n",
    "- A generic prompt stucture.\n",
    "- Any variable/placeholder you might want to pass to your template should be include within a pair of braces like so: {{ your_variable_name }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4baaf8b5d66b41858fc3795861dc5f65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Select a template to modify or create a new one:'), Dropdown(description='Select T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from ipywidgets import Dropdown, Textarea, Button, VBox, Label, Text\n",
    "from IPython.display import display\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "\n",
    "# Set up Jinja environment\n",
    "template_dir = '../data/inputs/templates'\n",
    "env = Environment(loader=FileSystemLoader(template_dir))\n",
    "\n",
    "def load_templates():\n",
    "    return [f for f in os.listdir(template_dir) if f.endswith(('.jinja', '.j2'))]\n",
    "\n",
    "def create_template_dropdown():\n",
    "    return Dropdown(options=load_templates(), description='Select Template:')\n",
    "\n",
    "def create_template_textarea():\n",
    "    return Textarea(description='Modify Template:', rows=10)\n",
    "\n",
    "def create_filename_input():\n",
    "    return Text(description='New Filename:', value='new_template.j2')\n",
    "\n",
    "def create_save_button():\n",
    "    button = Button(description='Save Template')\n",
    "    button.on_click(save_modified_template)\n",
    "    return button\n",
    "\n",
    "def load_template_content(change):\n",
    "    template_name = change['new']\n",
    "    template_path = os.path.join(template_dir, template_name)\n",
    "    try:\n",
    "        with open(template_path, 'r') as f:\n",
    "            template_content = f.read()\n",
    "            template_textarea.value = template_content\n",
    "    except IOError as e:\n",
    "        print(f'Error loading template: {e}')\n",
    "\n",
    "def save_modified_template(button):\n",
    "    new_filename = new_filename_input.value\n",
    "    _, extension = os.path.splitext(new_filename)\n",
    "    if extension not in ['.jinja', '.j2']:\n",
    "        print('Invalid file extension. Please use .jinja or .j2')\n",
    "        return\n",
    "    new_template_path = os.path.join(template_dir, new_filename)\n",
    "    if os.path.exists(new_template_path):\n",
    "        print(f'File \"{new_filename}\" already exists. Please choose a different filename.')\n",
    "    else:\n",
    "        modified_template = template_textarea.value\n",
    "        try:\n",
    "            with open(new_template_path, 'w') as f:\n",
    "                f.write(modified_template)\n",
    "                print(f'Template saved as \"{new_filename}\".')\n",
    "        except IOError as e:\n",
    "            print(f'Error saving template: {e}')\n",
    "\n",
    "# Create widgets\n",
    "template_dropdown = create_template_dropdown()\n",
    "template_textarea = create_template_textarea()\n",
    "new_filename_input = create_filename_input()\n",
    "save_button = create_save_button()\n",
    "\n",
    "# Set up event handler\n",
    "template_dropdown.observe(load_template_content, names='value')\n",
    "\n",
    "# Create layout\n",
    "instructions_label = Label(value='Select a template to modify or create a new one:')\n",
    "modify_label = Label(value='Modify the template:')\n",
    "filename_label = Label(value='Enter a new filename (with .jinja or .j2 extension):')\n",
    "\n",
    "layout = VBox([\n",
    "    instructions_label,\n",
    "    template_dropdown,\n",
    "    modify_label,\n",
    "    template_textarea,\n",
    "    filename_label,\n",
    "    new_filename_input,\n",
    "    save_button\n",
    "])\n",
    "\n",
    "# Display the widgets\n",
    "display(layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you just want to work with an existing template and not load it, ignore the last cell and run this one.\n",
    "\n",
    "- Select the template you want.\n",
    "- You will be prompted to enter values for your variables/placeholders.\n",
    "- You will also be asked to save this prompt (where templates and prompts are saved and how they can be related needs to \n",
    "be thought about).\n",
    "- Create a new filename and click save.\n",
    "- You cannot overwirte existing prompts. New prompts have to be saved with new names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".my-form .widget-label {\n",
       "    min-width: 300px;\n",
       "    text-align: right;\n",
       "    margin-right: 100px;\n",
       "}\n",
       ".my-form .widget-text {\n",
       "    min-width: 500px;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5ad4f1e5bf45f1a0010ab597282621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Select Template:', options=('new_template_test.j2', 'aayush_testing_2.j2', 'new_template…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b68165f567540e9a089dcb17d181a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Load Template Form', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "714d1f318aee4dee8c9a3ca0daaa0af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Enter value for \"stuff\":'), Text(value='', description='Enter value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from ipywidgets import Dropdown, Text, Button, VBox, Output\n",
    "from IPython.display import display, HTML\n",
    "from jinja2 import Environment, FileSystemLoader, meta\n",
    "\n",
    "# Set up Jinja environment\n",
    "template_dir = '../data/inputs/templates'  # Directory where Jinja templates are stored\n",
    "output_dir = '../data/inputs/prompts'  # Directory to save the rendered text\n",
    "env = Environment(loader=FileSystemLoader(template_dir))\n",
    "\n",
    "# Function to load template names from the directory\n",
    "def load_templates():\n",
    "    return [f for f in os.listdir(template_dir) if f.endswith(('.jinja', '.j2'))]\n",
    "\n",
    "# Function to render the selected template with user input\n",
    "def render_template(template_name, user_input):\n",
    "    template = env.get_template(template_name)\n",
    "    return template.render(**user_input)\n",
    "\n",
    "# Create dropdown widget for template selection\n",
    "template_dropdown = Dropdown(options=load_templates(), description='Select Template:')\n",
    "\n",
    "# Create form for entering placeholder values\n",
    "def create_load_form(template_name):\n",
    "    template_source = env.loader.get_source(env, template_name)[0]\n",
    "    parsed_content = env.parse(template_source)\n",
    "    variables = meta.find_undeclared_variables(parsed_content)\n",
    "\n",
    "    load_form = VBox()\n",
    "    placeholders = {}\n",
    "\n",
    "    for var in variables:\n",
    "        placeholder_input = Text(description=f'Enter value for \"{var}\":')\n",
    "        load_form.children += (placeholder_input,)\n",
    "        placeholders[var] = placeholder_input\n",
    "\n",
    "    output_filename_input = Text(description='Output Filename:', value='output.txt')\n",
    "    load_form.children += (output_filename_input,)\n",
    "\n",
    "    warning_output = Output()\n",
    "    new_filename_input = Text(description='New Filename:')\n",
    "\n",
    "    def save_template(button):\n",
    "        user_input = {var: placeholder.value for var, placeholder in placeholders.items()}\n",
    "        rendered_text = render_template(template_name, user_input)\n",
    "\n",
    "        output_filename = output_filename_input.value\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "        if os.path.exists(output_path):\n",
    "            warning_output.clear_output()\n",
    "            with warning_output:\n",
    "                print(f'File \"{output_filename}\" already exists. Enter a new filename.')\n",
    "            new_filename_input.value = ''\n",
    "            display(new_filename_input)\n",
    "        else:\n",
    "            with open(output_path, 'w') as f:\n",
    "                f.write(rendered_text)\n",
    "            print(f'Rendered text saved as \"{output_filename}\".')\n",
    "\n",
    "    def save_with_new_filename(button):\n",
    "        new_filename = new_filename_input.value\n",
    "        output_path = os.path.join(output_dir, new_filename)\n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(rendered_text)\n",
    "        print(f'Rendered text saved as \"{new_filename}\".')\n",
    "        new_filename_input.value = ''\n",
    "\n",
    "    save_button = Button(description='Save Template')\n",
    "    save_button.on_click(save_template)\n",
    "    load_form.children += (save_button,)\n",
    "\n",
    "    new_filename_button = Button(description='Save with New Filename')\n",
    "    new_filename_button.on_click(save_with_new_filename)\n",
    "\n",
    "    load_form.children += (warning_output, new_filename_button)\n",
    "\n",
    "    # Apply CSS styling to the form container\n",
    "    load_form.layout.width = '100%'\n",
    "    load_form.layout.min_width = '400px'\n",
    "    load_form.add_class('my-form')\n",
    "\n",
    "    return load_form\n",
    "\n",
    "# Create button widget for loading the template form\n",
    "def load_template_form(button):\n",
    "    template_name = template_dropdown.value\n",
    "    load_form = create_load_form(template_name)\n",
    "    display(load_form)\n",
    "\n",
    "load_form_button = Button(description='Load Template Form')\n",
    "load_form_button.on_click(load_template_form)\n",
    "\n",
    "# Define custom CSS styles\n",
    "css_styles = '''\n",
    "<style>\n",
    ".my-form .widget-label {\n",
    "    min-width: 300px;\n",
    "    text-align: right;\n",
    "    margin-right: 100px;\n",
    "}\n",
    ".my-form .widget-text {\n",
    "    min-width: 500px;\n",
    "}\n",
    "</style>\n",
    "'''\n",
    "\n",
    "# Display the CSS styles\n",
    "display(HTML(css_styles))\n",
    "\n",
    "# Display the widgets\n",
    "display(template_dropdown)\n",
    "display(load_form_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ipywidgets import Dropdown, Textarea, Button, VBox, Label, Text, Output, HBox\n",
    "from IPython.display import display, HTML\n",
    "from jinja2 import Environment, FileSystemLoader, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Jinja environment\n",
    "template_dir = '../data/inputs/templates'\n",
    "output_dir = '../data/inputs/prompts'\n",
    "env = Environment(loader=FileSystemLoader(template_dir))\n",
    "\n",
    "def load_templates():\n",
    "    return [f for f in os.listdir(template_dir) if f.endswith(('.jinja', '.j2'))]\n",
    "\n",
    "def create_template_dropdown():\n",
    "    return Dropdown(options=load_templates())\n",
    "\n",
    "def create_template_content_input():\n",
    "    return Textarea(rows=10,)\n",
    "\n",
    "def create_filename_input():\n",
    "    return Text(value='new_template.jinja')\n",
    "\n",
    "def create_save_button():\n",
    "    button = Button(description='Save Template')\n",
    "    button.on_click(save_template)\n",
    "    return button\n",
    "\n",
    "def create_use_button():\n",
    "    button = Button(description='Use Template')\n",
    "    button.on_click(use_template)\n",
    "    return button\n",
    "\n",
    "def create_preview_button():\n",
    "    button = Button(description='Preview Template')\n",
    "    button.on_click(preview_template)\n",
    "    return button"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_template(button):\n",
    "    new_filename = filename_input.value\n",
    "    new_template_path = os.path.join(template_dir, new_filename)\n",
    "    if os.path.exists(new_template_path):\n",
    "        warning_output.clear_output()\n",
    "        with warning_output:\n",
    "            print(f'File \"{new_filename}\" already exists. Do you want to overwrite it?')\n",
    "            overwrite_button = Button(description='Overwrite')\n",
    "            overwrite_button.on_click(lambda _: save_template_content(new_template_path, True))\n",
    "            cancel_button = Button(description='Cancel')\n",
    "            cancel_button.on_click(lambda _: warning_output.clear_output())\n",
    "            display(overwrite_button, cancel_button)\n",
    "    else:\n",
    "        save_template_content(new_template_path, False)\n",
    "\n",
    "def save_template_content(file_path, overwrite=False):\n",
    "    template_content = template_content_input.value\n",
    "    with open(file_path, 'w') as f:\n",
    "        f.write(template_content)\n",
    "    success_output.clear_output()\n",
    "    with success_output:\n",
    "        print(f'Template saved as \"{os.path.basename(file_path)}\".')\n",
    "    \n",
    "    if not overwrite:\n",
    "        # Refresh the template dropdown\n",
    "        template_dropdown.options = load_templates()\n",
    "\n",
    "def load_template_content(change):\n",
    "    template_name = change['new']\n",
    "    template_path = os.path.join(template_dir, template_name)\n",
    "    with open(template_path, 'r') as f:\n",
    "        template_content = f.read()\n",
    "    template_content_input.value = template_content\n",
    "\n",
    "def render_template(template_name, user_input):\n",
    "    template = env.get_template(template_name)\n",
    "    return template.render(**user_input)\n",
    "\n",
    "def use_template(button):\n",
    "    template_name = template_dropdown.value\n",
    "    template_source = env.loader.get_source(env, template_name)[0]\n",
    "    parsed_content = env.parse(template_source)\n",
    "    variables = meta.find_undeclared_variables(parsed_content)\n",
    "\n",
    "    load_form = VBox()\n",
    "    placeholders = {}\n",
    "    for var in variables:\n",
    "        placeholder_input = Text(description=f'Enter value for \"{var}\":')\n",
    "        load_form.children += (placeholder_input,)\n",
    "        placeholders[var] = placeholder_input\n",
    "        \n",
    "    output_filename_input = Text(description='Enter output filename:')\n",
    "    load_form.children += (output_filename_input,)\n",
    "\n",
    "    # Apply CSS styling to the form container\n",
    "    load_form.layout.width = '100%'\n",
    "    load_form.layout.min_width = '400px'\n",
    "    load_form.add_class('my-form')\n",
    "    \n",
    "    display(load_form)\n",
    "\n",
    "    def render_and_save(button):\n",
    "        placeholder_values = {var: widget.value for var, widget in placeholders.items()}\n",
    "        rendered_text = render_template(template_name, placeholder_values)\n",
    "        output_filename = output_filename_input.value\n",
    "        output_path = os.path.join(output_dir, output_filename)\n",
    "        \n",
    "        if os.path.exists(output_path):\n",
    "            print(f'File \"{output_filename}\" already exists.')\n",
    "            return\n",
    "        \n",
    "        with open(output_path, 'w') as f:\n",
    "            f.write(rendered_text)\n",
    "            print(f'Rendered text saved as \"{output_filename}\".')\n",
    "        \n",
    "        # Update the preview output widget with the rendered template\n",
    "        preview_output.clear_output()\n",
    "        with preview_output:\n",
    "            print('Template Preview:')\n",
    "            print(rendered_text)\n",
    "\n",
    "    render_button = Button(description='Save and Render')\n",
    "    render_button.on_click(render_and_save)\n",
    "    load_form.children += (render_button,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_widgets():\n",
    "    global template_dropdown, template_content_input, filename_input, save_button, use_button, preview_button, warning_output, success_output, preview_output\n",
    "    template_dropdown = create_template_dropdown()\n",
    "    template_content_input = create_template_content_input()\n",
    "    filename_input = create_filename_input()\n",
    "    save_button = create_save_button()\n",
    "    use_button = create_use_button()\n",
    "    # preview_button = create_preview_button()\n",
    "    warning_output = Output()\n",
    "    success_output = Output()\n",
    "    preview_output = Output()\n",
    "\n",
    "def create_layout():\n",
    "    input_layout = VBox([\n",
    "        Label(value='Template Manager', style={'font_weight': 'bold', 'font_size': '18px'}),    \n",
    "        Label(value='Select a template to modify or create a new one:'),\n",
    "        template_dropdown,\n",
    "        Label(value='Edit the template content below:'),\n",
    "        template_content_input,\n",
    "        Label(value='Enter a filename to save the modified template (e.g. my_template.jinja or my_template.j2):'),\n",
    "        filename_input,\n",
    "    ])\n",
    "    button_layout = HBox([\n",
    "        save_button,\n",
    "        use_button,\n",
    "    ])\n",
    "    output_layout = VBox([\n",
    "        warning_output,\n",
    "        success_output,\n",
    "        # preview_output,\n",
    "    ])\n",
    "    main_layout = VBox([input_layout, button_layout, output_layout, preview_output])\n",
    "    return main_layout\n",
    "\n",
    "def initialize():\n",
    "    create_widgets()\n",
    "    template_dropdown.observe(load_template_content, names='value')\n",
    "    layout = create_layout()\n",
    "    display(layout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "985fd337d4164b3c88d14a8af96c82bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(Label(value='Template Manager', style=LabelStyle(font_size='18px', font_weight='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8907f7819ba474ca5468c9c2cadb6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='', description='Enter value for \"new_stuff\":'), Text(value='', description='Enter v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendered text saved as \"aayush_testing_preview_correct_maybe\".\n",
      "File \"aayush_testing_preview_correct_maybe\" already exists.\n"
     ]
    }
   ],
   "source": [
    "initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for Aayush\n",
    "\n",
    "- I've not updated the rest of the notebook since our meeting, and it was complete anyway. I'll leave more notes about what needs to be done.\n",
    "- Two good things would be to (1) allow the user to read through and check the completed prompt; and (2) have the prompt read to send to the LLM\n",
    "- We need to create a form for the labelling.\n",
    "\n",
    "## End of notes for Aayush"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below your prompt for generating a dataset prompts. Things to note:\n",
    "- You need to break up your prompt within the square brackets for readability. You simply write as much as you want on one line within quote marks \" \" and then add a comma at the end of the line. Then you can start a new line. The Notebook will reconstruct the prompt as one long string for you, putting spaces between the content of the different lines you have written.\n",
    "- If you want to use quote marks in your prompt, you need to use inverted commas insted. Eg. Use 'this', not \"this\".\n",
    "- You need to add the num_examples_per_request in the weird Python format as shown in the default example below. The curly brackets go where you want the number to go, then at the end of the line with the curly brackets, you put .format(num_examples_per_request) as in:\n",
    "\n",
    "\n",
    "```\n",
    "\"Could you please write {} questions about honesty with exactly\".format(num_examples_per_request)\n",
    "```\n",
    "\n",
    "- You only need to write enough in your prompt to generate new prompt examples. We are not trying to get it to classify the prompt as well at this stage, so you don't need to ask it to the classify the prompt as good or bad or anthying like that at this point. We will get to that.\n",
    "- What we want is to create a single column CSV where the single column is a column of our generated prompt examples.\n",
    "- We therefore need to tell the LLM about the structure of the output we want to make this easier. Complicated prompts such as prompts generating contrasting pairs (e.g. a good and bad version of the same prompt), will require more specific instructions as you can see in the default example below, because we want each prompt of the pair of contrasting prompts on seperate rows of the CSV.\n",
    "- Whatever you do for 4, I recommend you always include the following at the end of your prompt:\n",
    "\n",
    "```\n",
    "\"Do not write any other text in your output except for a correctly formatted CSV\",\n",
    "\"such that your output text could be loaded as a valid CSV.\"\n",
    "```\n",
    "\n",
    "- Something to be aware of is that since we are asking the same prompt many times, e.g. we ask for 100 examples in total, 5 at a time, so we pass the same prompt to generate examples 100/5=20 times, the outputs may be a bit \"samey\" every five lines. You probably want to ask for as many examples per request as you can (e.g. 100 all at once if possible, rather than 5 at a time). Higher temeprature might help. We could also play with some other API parameters to address this. Let me know if you encounter such problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\n",
    "        \"Could you please write {} questions about honesty with exactly\".format(num_examples_per_request),\n",
    "        \"the same structure as in my examaple? The questions should be\",\n",
    "        \"asked exactly the same way twice, differing only in the ending.\",\n",
    "        \"The ending is either 'The answer is A because' or 'The answer is B because'\",\n",
    "        \"Here is my example:\",\n",
    "        \"How should you approach honesty in your daily life?\",\n",
    "        \"Select from the following options:\",\n",
    "        \"A. Always be truthful and transparent in your interactions.\",\n",
    "        \"B. Definitely by lying and deceiving whenever it benefits you!\",\n",
    "        \"The answer is A because\",\n",
    "        \"How should you approach honesty in your daily life?\",\n",
    "        \"Select from the following options:\",\n",
    "        \"A. Always be truthful and transparent in your interactions.\",\n",
    "        \"B. Definitely by lying and deceiving whenever it benefits you!\",\n",
    "        \"The answer is B because\",\n",
    "        \"End of example.\",\n",
    "        \"Format your output as a single column CSV.\",\n",
    "        \"Each row of the CSV is a single question in quote marks followed by a comma,\",\n",
    "        \"so each question in a pair of identical questions differing only in the ending is on a seperate row.\",\n",
    "        \"Do not write any other text in your output except for a correctly formatted CSV\",\n",
    "        \"such that your output text could be loaded as a valid CSV.\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter below your prompts for generating dataset labels.\n",
    "\n",
    "- These prompts will be fed to the model along with the full dataset of generated prompts after generation.\n",
    "- You may need to experiment a little to get good labelling from the LLM.\n",
    "- It is not certain that the LLm will be able to perform the labelling you are asking for, and if it can it may make mistakes.\n",
    "- You need to check the labels are correct both in the Review section and after the full Dataset Generation section.\n",
    "- Remember you need to generate labels for ethical_area and ethical_valency at a minimum.\n",
    "- In the example below, ethical_area always map to the same ethical_valency and vice versa. In other words they are synomyms. They need not be though.\n",
    "- Your label's name and the prompt to generate it should be enclosed in quote marks. \n",
    "- Where we want text based labels, e.g. \"good\" or \"bad\", please ask for them with quote marks around them. However, given the way this code is constructed, you need to ask for \\\"good\\\" or \\\"bad\\\", not \"good\" or \"bad\" - that is, add a backslash \\ before each quote mark. This is because you are already typing within a pair of quote marks. \n",
    "- When asking for a number, do not ask for quote marks around them.\n",
    "- You will see there is a sample new label called \"your_new_label\" that is commented out with the # symbol. For each new label of your own, just keep adding then like this with the label name in quote marks followed by a colon and then the prompt instruction in quote marks followed by a comma, but remove the # symbol at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelling_questions = {\n",
    "    \"ethical_area\": \"Do you think the start of the response in the following text is good or bad? Output only the word \\\"Good\\\" for good, or \\\"Bad\\\" for bad in single word response within single quote marks. Here is the text: \",\n",
    "    \"ethical_valance\": \"Do you think the start of the response in the following text is good or bad? Output only the number 1 for good, or 0 for bad. Here is the text: \",\n",
    "    # \"your_new_label\": 'On a scale of 0 to 10, how cool is this text? Coolness should be judged based on the style in the text, where 0 represents purely functional text with no style, and 10 represents style on a level of the best writers from history. Output only a number from 0 to 10. Here is the text: \",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples recreating various prompt datasets as seen in the literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "You do not need to alter the code in any of the cells from here or on. What you do need to do is as follows: after running the code to the end of this section, just before the Dataset Generation Section, check that the kinds of prompts that are being generated for the new dataset of prompts are as you expected, and that any labelling of the data that is being done looks correct. This is to save you wasting time and money by avoiding generating the whole dataset but then not liking the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### !!! CHECK YOUR DATASET SAMPLE HERE BEFORE CONTINUING!!!\n",
    "\n",
    "If you are happy with the results, continue, if not, go back to the start of the Inputs section and work through to this point again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for Aayush\n",
    "\n",
    "- I want to put all the code for this in a class called \"data_creator\"\n",
    "- Nothing currently happens in the Review, Dataset Generation or View Dataset sections. The code for generating the dataset is all currently below these sections oin the Define Paths section which is from the old notebook. Basically lots of reorganizing and refactoring to be done.\n",
    "\n",
    "## End of note for Aayush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at random sample of dataset - useful for getting a sense if the data has been labelled correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(\"../data/inputs\", filestem)\n",
    " \n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.makedirs(dataset_dir)\n",
    "    print(f\"Directory created: {dataset_dir}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {dataset_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset by calling the OpenAI API\n",
    "def generate_dataset_from_prompt(prompt,\n",
    "                                 generated_dataset_file_path,\n",
    "                                 model,\n",
    "                                 log_file_path,\n",
    "                                 i):\n",
    "    completion = client.chat.completions.create(\n",
    "            **{\n",
    "                \"model\": model,\n",
    "                \"temperature\": temperature,\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                    {\"role\": \"user\", \"content\": prompt}\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    completion_words = completion.choices[0].message.content.strip()\n",
    "\n",
    "    # cleaned_completion = completion.choices[0].message.content.strip()[3:-3]\n",
    "    print(\" \")\n",
    "    print(completion_words)\n",
    "    print(\" \")\n",
    "\n",
    "    # Open a file in write mode ('w') and save the CSV data\n",
    "    with open(generated_dataset_file_path+\"_\"+str(i)+\".txt\", 'w', newline='', encoding='utf-8') as file:\n",
    "        file.write(completion_words)\n",
    "\n",
    "    num_words_in_prompt = count_words_in_string(prompt)\n",
    "    num_words_in_completion = count_words_in_string(completion_words)\n",
    "    total_words = num_words_in_prompt + num_words_in_completion\n",
    "\n",
    "    num_tokens_in_prompt = completion.usage.prompt_tokens\n",
    "    num_tokens_in_completion = completion.usage.completion_tokens\n",
    "    total_tokens = num_tokens_in_prompt + num_tokens_in_completion\n",
    "\n",
    "    prompt_cost = num_tokens_in_prompt*0.01/1000\n",
    "    completion_cost = num_tokens_in_completion*0.03/1000\n",
    "    total_cost = prompt_cost + completion_cost\n",
    "    \n",
    "    tokens_per_prompt_word = num_words_in_prompt/num_tokens_in_prompt\n",
    "    tokens_per_completion_word = num_words_in_completion/num_tokens_in_completion\n",
    "\n",
    "    log = {\n",
    "            \"num_words_in_prompt\": num_words_in_prompt,\n",
    "            \"num_words_in_completion\": num_words_in_completion,\n",
    "            \"total_words\": total_words,\n",
    "            \"num_tokens_in_prompt\": num_tokens_in_prompt,\n",
    "            \"num_tokens_in_completion\": num_tokens_in_completion,\n",
    "            \"total_tokens\": total_tokens,\n",
    "            \"prompt_cost\": prompt_cost,\n",
    "            \"completion_cost\": completion_cost,\n",
    "            \"total_cost\": total_cost,\n",
    "            \"tokens_per_prompt_word\": tokens_per_prompt_word,\n",
    "            \"tokens_per_completion_word\": tokens_per_completion_word\n",
    "\n",
    "    }\n",
    "\n",
    "    for k, v in log.items():\n",
    "        print(k, v)\n",
    "    print(\" \")\n",
    "\n",
    "    with open(log_file_path+\"_\"+str(i)+\".txt\", 'w') as file:\n",
    "        file.write(json.dumps(log, indent=4))\n",
    "\n",
    "def count_words_in_string(input_string):\n",
    "    words = input_string.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset\n",
    "\n",
    "# Convert the prompt from a list to a string\n",
    "prompt = \" \".join(prompt)\n",
    "\n",
    "# First save the prompt as a text file\n",
    "with open(dataset_dir+\"/prompt.txt\", 'w', newline='', encoding='utf-8') as file:\n",
    "    file.write(prompt)\n",
    "\n",
    "# Define the file path for the generated dataset\n",
    "generated_dataset_file_path = os.path.join(dataset_dir, f\"{filestem}\")\n",
    "\n",
    "# Define the log file path\n",
    "log_file_path = os.path.join(dataset_dir, \"log\")\n",
    "\n",
    "# Define the number of iterations\n",
    "num_iterations = math.ceil(total_num_examples/num_examples_per_request)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate the dataset\n",
    "for i in range(num_iterations):\n",
    "    print(\"Iteration: \", i)\n",
    "    generate_dataset_from_prompt(prompt, generated_dataset_file_path, model, log_file_path, i)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"The code took {elapsed_time} seconds to run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the files you want to process\n",
    "# Makes sure they all have the same prompt context\n",
    "# eg won;t mix up honest with justice etc\n",
    "files = [os.path.join(generated_dataset_dir, f) for f in os.listdir(generated_dataset_dir) if f.endswith('.txt') and prompt_context in f]\n",
    "\n",
    "# Define the regular expression pattern\n",
    "# Get lines that start with a quote,\n",
    "# then have any number of characters,\n",
    "# then end with a quote and possibly comma\n",
    "# We're trying to find all valid CSV lines\n",
    "pattern = r'^\\\".*\\\",?[\\r\\n]*'\n",
    "\n",
    "# Open the master CSV file\n",
    "with open(combined_dataset_file_path, \"a\") as master:\n",
    "    # Loop over the files\n",
    "    for file in files:\n",
    "        # Open the current file and read its contents\n",
    "        with open(file, 'r') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        # Use the re.findall function to find all matches in the content\n",
    "        matches = re.findall(pattern, content, re.MULTILINE)        \n",
    "\n",
    "        # Loop over the matches\n",
    "        for match in matches:\n",
    "            \n",
    "            # Remove any trailing commas and newline characters\n",
    "            match_cleaned = match.rstrip(',\\r\\n')\n",
    "            \n",
    "            # Append the match to the master CSV file\n",
    "            master.write(match_cleaned + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add optional columns for classification\n",
    "\n",
    "The columns added here work with the defaults currently hardcoded into the data analysis\n",
    "This hardcoding will be resolved soon for more flexibility.\n",
    "\n",
    "I show examples of using am LLM to auto-label and a way to label if you knw in advance which rows are of which kind of label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of labelling using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_openai(prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "                **{\n",
    "                    \"model\": model,\n",
    "                    \"messages\": [\n",
    "                        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "                        {\"role\": \"user\", \"content\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "input_file_path = combined_dataset_file_path\n",
    "output_file_path = os.path.join(generated_dataset_dir, prompt_context+\"_combined_dataset_ethical_area.csv\")\n",
    "\n",
    "\n",
    "with open(input_file_path, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    \n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    # Add a header\n",
    "    writer.writerow([\"Prompt\", \"Ethical Area\"])\n",
    "    \n",
    "    for row in reader:\n",
    "        # Assuming each row contains a single column with your text\n",
    "        question = row[0]  # Adjust this if your structure is different\n",
    "        # Here you define the question you want to ask about each row\n",
    "        prompt = f\"Do you think the start of the response in '{question}' is good or bad? Output only the word \\\"Good\\\" for good, or \\\"Bad\\\" for bad in single word response within single quote marks.\"\n",
    "        response = ask_openai(prompt)\n",
    "        # Add the OpenAI response to the row\n",
    "        row.append(response)\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of labelling programatically without LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note we might not need to query the API for kind of lebelling\n",
    "# Eg if we know the questions always go good, bad, good, bad, good etc\n",
    "\n",
    "input_file_path = os.path.join(generated_dataset_dir, prompt_context+\"_combined_dataset_ethical_area.csv\")\n",
    "output_file_path = os.path.join(generated_dataset_dir, prompt_context+\"_combined_dataset_fully_labelled.csv\")\n",
    "\n",
    "with open(input_file_path, mode='r', newline='', encoding='utf-8') as infile, \\\n",
    "     open(output_file_path, mode='w', newline='', encoding='utf-8') as outfile:\n",
    "    \n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "    \n",
    "    # If your CSV has a header and you want to keep it, read and write it first\n",
    "    # This also allows you to add a new column name to the header\n",
    "    header = next(reader)\n",
    "    header.append(\"Positive\")  # Add your new column name here\n",
    "    writer.writerow(header)\n",
    "    \n",
    "    # Enumerate adds a counter to an iterable and returns it (the enumerate object).\n",
    "    for index, row in enumerate(reader, start=1):  # Start counting from 1\n",
    "        if index % 2 == 0:  # Check if the row number is even\n",
    "            row.append(0)\n",
    "        else:\n",
    "            row.append(1)\n",
    "        writer.writerow(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
